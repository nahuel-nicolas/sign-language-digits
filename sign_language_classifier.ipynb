{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sign Language Digits Classifier\n",
    "Using MobileNet transfer learning to classify ASL digits (0-9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.applications import MobileNetV2, MobileNet, MobileNetV3Small\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.applications.mobilenet import preprocess_input\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.10.1\n",
      "Built with CUDA: True\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"Built with CUDA:\", tf.test.is_built_with_cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(\"Num GPUs Available: \", len(physical_devices))\n",
    "if physical_devices:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Set Project Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project constants\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 30\n",
    "VALIDATION_SPLIT = 0.2\n",
    "NUM_CLASSES = 10\n",
    "\n",
    "# Paths\n",
    "DATASET_PATH = 'Sign-Language-Digits-Dataset/Dataset'\n",
    "TRAIN_PATH = 'Sign-Language-Digits-Dataset/training'\n",
    "TEST_PATH = 'Sign-Language-Digits-Dataset/test'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create Dataset Splits\n",
    "Creating training/ folder (85% of dataset) and test/ folder (15% of dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating training/test split...\n",
      "Digit 0: 175 training, 30 test\n",
      "Digit 1: 176 training, 30 test\n",
      "Digit 2: 176 training, 30 test\n",
      "Digit 3: 176 training, 30 test\n",
      "Digit 4: 176 training, 31 test\n",
      "Digit 5: 176 training, 31 test\n",
      "Digit 6: 176 training, 31 test\n",
      "Digit 7: 176 training, 30 test\n",
      "Digit 8: 177 training, 31 test\n",
      "Digit 9: 174 training, 30 test\n",
      "\n",
      "Total training images: 1758 (85.3%)\n",
      "Total test images: 304 (14.7%)\n"
     ]
    }
   ],
   "source": [
    "# Create training/ and test/ folders with 85/15 split\n",
    "def create_train_test_split(source_path, train_path, test_path, test_split=0.15):\n",
    "    \"\"\"Split dataset into training (85%) and test (15%) folders\"\"\"\n",
    "    \n",
    "    # Remove destination folders if they exist\n",
    "    for path in [train_path, test_path]:\n",
    "        if os.path.exists(path):\n",
    "            shutil.rmtree(path)\n",
    "        os.makedirs(path)\n",
    "    \n",
    "    total_train_images = 0\n",
    "    total_test_images = 0\n",
    "    \n",
    "    # Process each digit (0-9)\n",
    "    for digit in range(10):\n",
    "        digit_source = os.path.join(source_path, str(digit))\n",
    "        digit_train = os.path.join(train_path, str(digit))\n",
    "        digit_test = os.path.join(test_path, str(digit))\n",
    "        \n",
    "        os.makedirs(digit_train)\n",
    "        os.makedirs(digit_test)\n",
    "        \n",
    "        # Get all images for this digit\n",
    "        all_images = [f for f in os.listdir(digit_source) if f.endswith('.JPG')]\n",
    "        \n",
    "        # Shuffle images\n",
    "        random.shuffle(all_images)\n",
    "        \n",
    "        # Calculate split point (15% for test, 85% for training)\n",
    "        num_test = int(len(all_images) * test_split)\n",
    "        num_train = len(all_images) - num_test\n",
    "        \n",
    "        # Split images\n",
    "        test_images = all_images[:num_test]\n",
    "        train_images = all_images[num_test:]\n",
    "        \n",
    "        # Copy test images\n",
    "        for img in test_images:\n",
    "            src = os.path.join(digit_source, img)\n",
    "            dst = os.path.join(digit_test, img)\n",
    "            shutil.copy2(src, dst)\n",
    "        \n",
    "        # Copy training images\n",
    "        for img in train_images:\n",
    "            src = os.path.join(digit_source, img)\n",
    "            dst = os.path.join(digit_train, img)\n",
    "            shutil.copy2(src, dst)\n",
    "        \n",
    "        total_train_images += num_train\n",
    "        total_test_images += num_test\n",
    "        \n",
    "        print(f'Digit {digit}: {num_train} training, {num_test} test')\n",
    "    \n",
    "    return total_train_images, total_test_images\n",
    "\n",
    "print('Creating training/test split...')\n",
    "num_train, num_test = create_train_test_split(DATASET_PATH, TRAIN_PATH, TEST_PATH)\n",
    "\n",
    "print(f'\\nTotal training images: {num_train} ({num_train/(num_train+num_test)*100:.1f}%)')\n",
    "print(f'Total test images: {num_test} ({num_test/(num_train+num_test)*100:.1f}%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create Data Generators\n",
    "Setting up training and validation generators with 80/20 split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1409 images belonging to 10 classes.\n",
      "Found 349 images belonging to 10 classes.\n",
      "\n",
      "Training samples: 1409\n",
      "Validation samples: 349\n"
     ]
    }
   ],
   "source": [
    "# Create image data generators with data augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "    validation_split=VALIDATION_SPLIT,\n",
    "    # Data augmentation parameters\n",
    "    rotation_range=15,              # Randomly rotate images by up to 15 degrees\n",
    "    zoom_range=0.15,                # Randomly zoom in/out by up to 15%\n",
    "    brightness_range=[0.8, 1.2],    # Randomly adjust brightness\n",
    "    fill_mode='nearest'             # Fill pixels after transformations\n",
    ")\n",
    "\n",
    "# Validation generator (no augmentation, only rescaling)\n",
    "val_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "    validation_split=VALIDATION_SPLIT\n",
    ")\n",
    "\n",
    "# Training generator\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    TRAIN_PATH,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    subset='training',\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# Validation generator\n",
    "validation_generator = val_datagen.flow_from_directory(\n",
    "    TRAIN_PATH,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    subset='validation',\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "print(f'\\nTraining samples: {train_generator.samples}')\n",
    "print(f'Validation samples: {validation_generator.samples}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Compare Mobilenet V1, V2 and V3Small\n",
    "Tune the model, compile it and train it for each of these"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_model.trainable = False\n",
    "\n",
    "# Build model on top of MobileNet\n",
    "def get_predictions_layer(base_model_output):\n",
    "    x = GlobalAveragePooling2D()(base_model_output)\n",
    "    predictions = Dense(\n",
    "        NUM_CLASSES,\n",
    "        activation='softmax',\n",
    "        # kernel_regularizer=regularizers.l2(0.1)\n",
    "    )(x)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6),\n",
    "    EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### V1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: conv_dw_10\n",
      "  Type: DepthwiseConv2D\n",
      "  Output Shape: (None, 14, 14, 512)\n",
      "  Params: 4608\n",
      "--------------------------------------------------\n",
      "Layer: conv_dw_10_bn\n",
      "  Type: BatchNormalization\n",
      "  Output Shape: (None, 14, 14, 512)\n",
      "  Params: 2048\n",
      "--------------------------------------------------\n",
      "Layer: conv_dw_10_relu\n",
      "  Type: ReLU\n",
      "  Output Shape: (None, 14, 14, 512)\n",
      "  Params: 0\n",
      "--------------------------------------------------\n",
      "Layer: conv_pw_10\n",
      "  Type: Conv2D\n",
      "  Output Shape: (None, 14, 14, 512)\n",
      "  Params: 262144\n",
      "--------------------------------------------------\n",
      "Layer: conv_pw_10_bn\n",
      "  Type: BatchNormalization\n",
      "  Output Shape: (None, 14, 14, 512)\n",
      "  Params: 2048\n",
      "--------------------------------------------------\n",
      "Layer: conv_pw_10_relu\n",
      "  Type: ReLU\n",
      "  Output Shape: (None, 14, 14, 512)\n",
      "  Params: 0\n",
      "--------------------------------------------------\n",
      "Layer: conv_dw_11\n",
      "  Type: DepthwiseConv2D\n",
      "  Output Shape: (None, 14, 14, 512)\n",
      "  Params: 4608\n",
      "--------------------------------------------------\n",
      "Layer: conv_dw_11_bn\n",
      "  Type: BatchNormalization\n",
      "  Output Shape: (None, 14, 14, 512)\n",
      "  Params: 2048\n",
      "--------------------------------------------------\n",
      "Layer: conv_dw_11_relu\n",
      "  Type: ReLU\n",
      "  Output Shape: (None, 14, 14, 512)\n",
      "  Params: 0\n",
      "--------------------------------------------------\n",
      "Layer: conv_pw_11\n",
      "  Type: Conv2D\n",
      "  Output Shape: (None, 14, 14, 512)\n",
      "  Params: 262144\n",
      "--------------------------------------------------\n",
      "Layer: conv_pw_11_bn\n",
      "  Type: BatchNormalization\n",
      "  Output Shape: (None, 14, 14, 512)\n",
      "  Params: 2048\n",
      "--------------------------------------------------\n",
      "Layer: conv_pw_11_relu\n",
      "  Type: ReLU\n",
      "  Output Shape: (None, 14, 14, 512)\n",
      "  Params: 0\n",
      "--------------------------------------------------\n",
      "Layer: conv_pad_12\n",
      "  Type: ZeroPadding2D\n",
      "  Output Shape: (None, 15, 15, 512)\n",
      "  Params: 0\n",
      "--------------------------------------------------\n",
      "Layer: conv_dw_12\n",
      "  Type: DepthwiseConv2D\n",
      "  Output Shape: (None, 7, 7, 512)\n",
      "  Params: 4608\n",
      "--------------------------------------------------\n",
      "Layer: conv_dw_12_bn\n",
      "  Type: BatchNormalization\n",
      "  Output Shape: (None, 7, 7, 512)\n",
      "  Params: 2048\n",
      "--------------------------------------------------\n",
      "Layer: conv_dw_12_relu\n",
      "  Type: ReLU\n",
      "  Output Shape: (None, 7, 7, 512)\n",
      "  Params: 0\n",
      "--------------------------------------------------\n",
      "Layer: conv_pw_12\n",
      "  Type: Conv2D\n",
      "  Output Shape: (None, 7, 7, 1024)\n",
      "  Params: 524288\n",
      "--------------------------------------------------\n",
      "Layer: conv_pw_12_bn\n",
      "  Type: BatchNormalization\n",
      "  Output Shape: (None, 7, 7, 1024)\n",
      "  Params: 4096\n",
      "--------------------------------------------------\n",
      "Layer: conv_pw_12_relu\n",
      "  Type: ReLU\n",
      "  Output Shape: (None, 7, 7, 1024)\n",
      "  Params: 0\n",
      "--------------------------------------------------\n",
      "Layer: conv_dw_13\n",
      "  Type: DepthwiseConv2D\n",
      "  Output Shape: (None, 7, 7, 1024)\n",
      "  Params: 9216\n",
      "--------------------------------------------------\n",
      "Layer: conv_dw_13_bn\n",
      "  Type: BatchNormalization\n",
      "  Output Shape: (None, 7, 7, 1024)\n",
      "  Params: 4096\n",
      "--------------------------------------------------\n",
      "Layer: conv_dw_13_relu\n",
      "  Type: ReLU\n",
      "  Output Shape: (None, 7, 7, 1024)\n",
      "  Params: 0\n",
      "--------------------------------------------------\n",
      "Layer: conv_pw_13\n",
      "  Type: Conv2D\n",
      "  Output Shape: (None, 7, 7, 1024)\n",
      "  Params: 1048576\n",
      "--------------------------------------------------\n",
      "Layer: conv_pw_13_bn\n",
      "  Type: BatchNormalization\n",
      "  Output Shape: (None, 7, 7, 1024)\n",
      "  Params: 4096\n",
      "--------------------------------------------------\n",
      "Layer: conv_pw_13_relu\n",
      "  Type: ReLU\n",
      "  Output Shape: (None, 7, 7, 1024)\n",
      "  Params: 0\n",
      "--------------------------------------------------\n",
      "Layer: global_average_pooling2d_6\n",
      "  Type: GlobalAveragePooling2D\n",
      "  Output Shape: (None, 1, 1, 1024)\n",
      "  Params: 0\n",
      "--------------------------------------------------\n",
      "Layer: dropout\n",
      "  Type: Dropout\n",
      "  Output Shape: (None, 1, 1, 1024)\n",
      "  Params: 0\n",
      "--------------------------------------------------\n",
      "Layer: conv_preds\n",
      "  Type: Conv2D\n",
      "  Output Shape: (None, 1, 1, 1000)\n",
      "  Params: 1025000\n",
      "--------------------------------------------------\n",
      "Layer: reshape_2\n",
      "  Type: Reshape\n",
      "  Output Shape: (None, 1000)\n",
      "  Params: 0\n",
      "--------------------------------------------------\n",
      "Layer: predictions\n",
      "  Type: Activation\n",
      "  Output Shape: (None, 1000)\n",
      "  Params: 0\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "base_model = MobileNet(\n",
    "    include_top=True, \n",
    "    weights='imagenet'\n",
    ")\n",
    "\n",
    "\n",
    "for layer in base_model.layers[-30:]:\n",
    "    print(f\"Layer: {layer.name}\")\n",
    "    print(f\"  Type: {layer.__class__.__name__}\")\n",
    "    print(f\"  Output Shape: {layer.output.shape}\")\n",
    "    print(f\"  Params: {layer.count_params()}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model architecture:\n",
      "Layer: conv_dw_11_bn\n",
      "  Type: BatchNormalization\n",
      "  Output Shape: (None, 14, 14, 512)\n",
      "  Params: 2048\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: conv_dw_11_relu\n",
      "  Type: ReLU\n",
      "  Output Shape: (None, 14, 14, 512)\n",
      "  Params: 0\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: conv_pw_11\n",
      "  Type: Conv2D\n",
      "  Output Shape: (None, 14, 14, 512)\n",
      "  Params: 262144\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: conv_pw_11_bn\n",
      "  Type: BatchNormalization\n",
      "  Output Shape: (None, 14, 14, 512)\n",
      "  Params: 2048\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: conv_pw_11_relu\n",
      "  Type: ReLU\n",
      "  Output Shape: (None, 14, 14, 512)\n",
      "  Params: 0\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: conv_pad_12\n",
      "  Type: ZeroPadding2D\n",
      "  Output Shape: (None, 15, 15, 512)\n",
      "  Params: 0\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: conv_dw_12\n",
      "  Type: DepthwiseConv2D\n",
      "  Output Shape: (None, 7, 7, 512)\n",
      "  Params: 4608\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: conv_dw_12_bn\n",
      "  Type: BatchNormalization\n",
      "  Output Shape: (None, 7, 7, 512)\n",
      "  Params: 2048\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: conv_dw_12_relu\n",
      "  Type: ReLU\n",
      "  Output Shape: (None, 7, 7, 512)\n",
      "  Params: 0\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: conv_pw_12\n",
      "  Type: Conv2D\n",
      "  Output Shape: (None, 7, 7, 1024)\n",
      "  Params: 524288\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: conv_pw_12_bn\n",
      "  Type: BatchNormalization\n",
      "  Output Shape: (None, 7, 7, 1024)\n",
      "  Params: 4096\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: conv_pw_12_relu\n",
      "  Type: ReLU\n",
      "  Output Shape: (None, 7, 7, 1024)\n",
      "  Params: 0\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: conv_dw_13\n",
      "  Type: DepthwiseConv2D\n",
      "  Output Shape: (None, 7, 7, 1024)\n",
      "  Params: 9216\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: conv_dw_13_bn\n",
      "  Type: BatchNormalization\n",
      "  Output Shape: (None, 7, 7, 1024)\n",
      "  Params: 4096\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: conv_dw_13_relu\n",
      "  Type: ReLU\n",
      "  Output Shape: (None, 7, 7, 1024)\n",
      "  Params: 0\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: conv_pw_13\n",
      "  Type: Conv2D\n",
      "  Output Shape: (None, 7, 7, 1024)\n",
      "  Params: 1048576\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: conv_pw_13_bn\n",
      "  Type: BatchNormalization\n",
      "  Output Shape: (None, 7, 7, 1024)\n",
      "  Params: 4096\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: conv_pw_13_relu\n",
      "  Type: ReLU\n",
      "  Output Shape: (None, 7, 7, 1024)\n",
      "  Params: 0\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: global_average_pooling2d_7\n",
      "  Type: GlobalAveragePooling2D\n",
      "  Output Shape: (None, 1024)\n",
      "  Params: 0\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: dense_7\n",
      "  Type: Dense\n",
      "  Output Shape: (None, 10)\n",
      "  Params: 10250\n",
      " Trainable: True\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "x = base_model.get_layer(\"conv_pw_13_relu\").output\n",
    "predictions = get_predictions_layer(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "for layer in model.layers[:-1]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compile model\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print('\\nModel architecture:')\n",
    "for layer in model.layers[-20:]:\n",
    "    print(f\"Layer: {layer.name}\")\n",
    "    print(f\"  Type: {layer.__class__.__name__}\")\n",
    "    print(f\"  Output Shape: {layer.output.shape}\")\n",
    "    print(f\"  Params: {layer.count_params()}\")\n",
    "    print(f\" Trainable: {layer.trainable}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "45/45 [==============================] - 24s 511ms/step - loss: 1.6671 - accuracy: 0.4734 - val_loss: 1.2649 - val_accuracy: 0.6848 - lr: 0.0010\n",
      "Epoch 2/30\n",
      "45/45 [==============================] - 11s 245ms/step - loss: 0.9324 - accuracy: 0.7750 - val_loss: 0.9705 - val_accuracy: 0.7192 - lr: 0.0010\n",
      "Epoch 3/30\n",
      "45/45 [==============================] - 11s 247ms/step - loss: 0.6623 - accuracy: 0.8581 - val_loss: 0.7950 - val_accuracy: 0.7650 - lr: 0.0010\n",
      "Epoch 4/30\n",
      "45/45 [==============================] - 11s 247ms/step - loss: 0.5392 - accuracy: 0.8914 - val_loss: 0.7329 - val_accuracy: 0.7736 - lr: 0.0010\n",
      "Epoch 5/30\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.4722 - accuracy: 0.8900 - val_loss: 0.6574 - val_accuracy: 0.8166 - lr: 0.0010\n",
      "Epoch 6/30\n",
      "45/45 [==============================] - 11s 248ms/step - loss: 0.4022 - accuracy: 0.9148 - val_loss: 0.6931 - val_accuracy: 0.7622 - lr: 0.0010\n",
      "Epoch 7/30\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.3483 - accuracy: 0.9283 - val_loss: 0.5784 - val_accuracy: 0.8252 - lr: 0.0010\n",
      "Epoch 8/30\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.3205 - accuracy: 0.9241 - val_loss: 0.5745 - val_accuracy: 0.8138 - lr: 0.0010\n",
      "Epoch 9/30\n",
      "45/45 [==============================] - 11s 249ms/step - loss: 0.2906 - accuracy: 0.9446 - val_loss: 0.6049 - val_accuracy: 0.7966 - lr: 0.0010\n",
      "Epoch 10/30\n",
      "45/45 [==============================] - 11s 243ms/step - loss: 0.2726 - accuracy: 0.9461 - val_loss: 0.5788 - val_accuracy: 0.8052 - lr: 0.0010\n",
      "Epoch 11/30\n",
      "45/45 [==============================] - 11s 248ms/step - loss: 0.2589 - accuracy: 0.9439 - val_loss: 0.5552 - val_accuracy: 0.8138 - lr: 0.0010\n",
      "Epoch 12/30\n",
      "45/45 [==============================] - 11s 248ms/step - loss: 0.2416 - accuracy: 0.9574 - val_loss: 0.5173 - val_accuracy: 0.8309 - lr: 0.0010\n",
      "Epoch 13/30\n",
      "45/45 [==============================] - 11s 245ms/step - loss: 0.2344 - accuracy: 0.9468 - val_loss: 0.5312 - val_accuracy: 0.8281 - lr: 0.0010\n",
      "Epoch 14/30\n",
      "45/45 [==============================] - 11s 247ms/step - loss: 0.2318 - accuracy: 0.9475 - val_loss: 0.4856 - val_accuracy: 0.8195 - lr: 0.0010\n",
      "Epoch 15/30\n",
      "45/45 [==============================] - 11s 246ms/step - loss: 0.1991 - accuracy: 0.9652 - val_loss: 0.4986 - val_accuracy: 0.8309 - lr: 0.0010\n",
      "Epoch 16/30\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.1906 - accuracy: 0.9603 - val_loss: 0.5219 - val_accuracy: 0.8138 - lr: 0.0010\n",
      "Epoch 17/30\n",
      "45/45 [==============================] - 11s 247ms/step - loss: 0.1779 - accuracy: 0.9666 - val_loss: 0.4671 - val_accuracy: 0.8453 - lr: 0.0010\n",
      "Epoch 18/30\n",
      "45/45 [==============================] - 11s 247ms/step - loss: 0.1708 - accuracy: 0.9631 - val_loss: 0.4282 - val_accuracy: 0.8596 - lr: 0.0010\n",
      "Epoch 19/30\n",
      "45/45 [==============================] - 11s 246ms/step - loss: 0.1597 - accuracy: 0.9638 - val_loss: 0.4707 - val_accuracy: 0.8395 - lr: 0.0010\n",
      "Epoch 20/30\n",
      "45/45 [==============================] - 11s 245ms/step - loss: 0.1571 - accuracy: 0.9695 - val_loss: 0.4209 - val_accuracy: 0.8567 - lr: 0.0010\n",
      "Epoch 21/30\n",
      "45/45 [==============================] - 11s 247ms/step - loss: 0.1504 - accuracy: 0.9737 - val_loss: 0.4336 - val_accuracy: 0.8596 - lr: 0.0010\n",
      "Epoch 22/30\n",
      "45/45 [==============================] - 11s 244ms/step - loss: 0.1478 - accuracy: 0.9688 - val_loss: 0.4707 - val_accuracy: 0.8395 - lr: 0.0010\n",
      "Epoch 23/30\n",
      "45/45 [==============================] - 11s 246ms/step - loss: 0.1426 - accuracy: 0.9759 - val_loss: 0.4363 - val_accuracy: 0.8510 - lr: 0.0010\n",
      "Epoch 24/30\n",
      "45/45 [==============================] - 12s 273ms/step - loss: 0.1278 - accuracy: 0.9844 - val_loss: 0.4108 - val_accuracy: 0.8682 - lr: 5.0000e-04\n",
      "Epoch 25/30\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.1279 - accuracy: 0.9766 - val_loss: 0.4454 - val_accuracy: 0.8367 - lr: 5.0000e-04\n",
      "Epoch 26/30\n",
      "45/45 [==============================] - 11s 248ms/step - loss: 0.1249 - accuracy: 0.9752 - val_loss: 0.4046 - val_accuracy: 0.8682 - lr: 5.0000e-04\n",
      "Epoch 27/30\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.1331 - accuracy: 0.9730 - val_loss: 0.4279 - val_accuracy: 0.8510 - lr: 5.0000e-04\n",
      "Epoch 28/30\n",
      "45/45 [==============================] - 11s 249ms/step - loss: 0.1170 - accuracy: 0.9794 - val_loss: 0.3935 - val_accuracy: 0.8567 - lr: 5.0000e-04\n",
      "Epoch 29/30\n",
      "45/45 [==============================] - 11s 249ms/step - loss: 0.1241 - accuracy: 0.9752 - val_loss: 0.4101 - val_accuracy: 0.8539 - lr: 5.0000e-04\n",
      "Epoch 30/30\n",
      "45/45 [==============================] - 11s 248ms/step - loss: 0.1138 - accuracy: 0.9823 - val_loss: 0.3896 - val_accuracy: 0.8625 - lr: 5.0000e-04\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=validation_generator,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=callbacks + [ModelCheckpoint('mobilenet.h5', save_best_only=True)],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: block_15_expand_relu\n",
      "  Type: ReLU\n",
      "  Output Shape: (None, 7, 7, 960)\n",
      "  Params: 0\n",
      "--------------------------------------------------\n",
      "Layer: block_15_depthwise\n",
      "  Type: DepthwiseConv2D\n",
      "  Output Shape: (None, 7, 7, 960)\n",
      "  Params: 8640\n",
      "--------------------------------------------------\n",
      "Layer: block_15_depthwise_BN\n",
      "  Type: BatchNormalization\n",
      "  Output Shape: (None, 7, 7, 960)\n",
      "  Params: 3840\n",
      "--------------------------------------------------\n",
      "Layer: block_15_depthwise_relu\n",
      "  Type: ReLU\n",
      "  Output Shape: (None, 7, 7, 960)\n",
      "  Params: 0\n",
      "--------------------------------------------------\n",
      "Layer: block_15_project\n",
      "  Type: Conv2D\n",
      "  Output Shape: (None, 7, 7, 160)\n",
      "  Params: 153600\n",
      "--------------------------------------------------\n",
      "Layer: block_15_project_BN\n",
      "  Type: BatchNormalization\n",
      "  Output Shape: (None, 7, 7, 160)\n",
      "  Params: 640\n",
      "--------------------------------------------------\n",
      "Layer: block_15_add\n",
      "  Type: Add\n",
      "  Output Shape: (None, 7, 7, 160)\n",
      "  Params: 0\n",
      "--------------------------------------------------\n",
      "Layer: block_16_expand\n",
      "  Type: Conv2D\n",
      "  Output Shape: (None, 7, 7, 960)\n",
      "  Params: 153600\n",
      "--------------------------------------------------\n",
      "Layer: block_16_expand_BN\n",
      "  Type: BatchNormalization\n",
      "  Output Shape: (None, 7, 7, 960)\n",
      "  Params: 3840\n",
      "--------------------------------------------------\n",
      "Layer: block_16_expand_relu\n",
      "  Type: ReLU\n",
      "  Output Shape: (None, 7, 7, 960)\n",
      "  Params: 0\n",
      "--------------------------------------------------\n",
      "Layer: block_16_depthwise\n",
      "  Type: DepthwiseConv2D\n",
      "  Output Shape: (None, 7, 7, 960)\n",
      "  Params: 8640\n",
      "--------------------------------------------------\n",
      "Layer: block_16_depthwise_BN\n",
      "  Type: BatchNormalization\n",
      "  Output Shape: (None, 7, 7, 960)\n",
      "  Params: 3840\n",
      "--------------------------------------------------\n",
      "Layer: block_16_depthwise_relu\n",
      "  Type: ReLU\n",
      "  Output Shape: (None, 7, 7, 960)\n",
      "  Params: 0\n",
      "--------------------------------------------------\n",
      "Layer: block_16_project\n",
      "  Type: Conv2D\n",
      "  Output Shape: (None, 7, 7, 320)\n",
      "  Params: 307200\n",
      "--------------------------------------------------\n",
      "Layer: block_16_project_BN\n",
      "  Type: BatchNormalization\n",
      "  Output Shape: (None, 7, 7, 320)\n",
      "  Params: 1280\n",
      "--------------------------------------------------\n",
      "Layer: Conv_1\n",
      "  Type: Conv2D\n",
      "  Output Shape: (None, 7, 7, 1280)\n",
      "  Params: 409600\n",
      "--------------------------------------------------\n",
      "Layer: Conv_1_bn\n",
      "  Type: BatchNormalization\n",
      "  Output Shape: (None, 7, 7, 1280)\n",
      "  Params: 5120\n",
      "--------------------------------------------------\n",
      "Layer: out_relu\n",
      "  Type: ReLU\n",
      "  Output Shape: (None, 7, 7, 1280)\n",
      "  Params: 0\n",
      "--------------------------------------------------\n",
      "Layer: global_average_pooling2d_12\n",
      "  Type: GlobalAveragePooling2D\n",
      "  Output Shape: (None, 1280)\n",
      "  Params: 0\n",
      "--------------------------------------------------\n",
      "Layer: predictions\n",
      "  Type: Dense\n",
      "  Output Shape: (None, 1000)\n",
      "  Params: 1281000\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "base_model = MobileNetV2(\n",
    "    include_top=True, \n",
    "    weights='imagenet'\n",
    ")\n",
    "\n",
    "for layer in base_model.layers[-20:]:\n",
    "    print(f\"Layer: {layer.name}\")\n",
    "    print(f\"  Type: {layer.__class__.__name__}\")\n",
    "    print(f\"  Output Shape: {layer.output.shape}\")\n",
    "    print(f\"  Params: {layer.count_params()}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model architecture:\n",
      "Layer: block_15_expand_relu\n",
      "  Type: ReLU\n",
      "  Output Shape: (None, 7, 7, 960)\n",
      "  Params: 0\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: block_15_depthwise\n",
      "  Type: DepthwiseConv2D\n",
      "  Output Shape: (None, 7, 7, 960)\n",
      "  Params: 8640\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: block_15_depthwise_BN\n",
      "  Type: BatchNormalization\n",
      "  Output Shape: (None, 7, 7, 960)\n",
      "  Params: 3840\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: block_15_depthwise_relu\n",
      "  Type: ReLU\n",
      "  Output Shape: (None, 7, 7, 960)\n",
      "  Params: 0\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: block_15_project\n",
      "  Type: Conv2D\n",
      "  Output Shape: (None, 7, 7, 160)\n",
      "  Params: 153600\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: block_15_project_BN\n",
      "  Type: BatchNormalization\n",
      "  Output Shape: (None, 7, 7, 160)\n",
      "  Params: 640\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: block_15_add\n",
      "  Type: Add\n",
      "  Output Shape: (None, 7, 7, 160)\n",
      "  Params: 0\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: block_16_expand\n",
      "  Type: Conv2D\n",
      "  Output Shape: (None, 7, 7, 960)\n",
      "  Params: 153600\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: block_16_expand_BN\n",
      "  Type: BatchNormalization\n",
      "  Output Shape: (None, 7, 7, 960)\n",
      "  Params: 3840\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: block_16_expand_relu\n",
      "  Type: ReLU\n",
      "  Output Shape: (None, 7, 7, 960)\n",
      "  Params: 0\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: block_16_depthwise\n",
      "  Type: DepthwiseConv2D\n",
      "  Output Shape: (None, 7, 7, 960)\n",
      "  Params: 8640\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: block_16_depthwise_BN\n",
      "  Type: BatchNormalization\n",
      "  Output Shape: (None, 7, 7, 960)\n",
      "  Params: 3840\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: block_16_depthwise_relu\n",
      "  Type: ReLU\n",
      "  Output Shape: (None, 7, 7, 960)\n",
      "  Params: 0\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: block_16_project\n",
      "  Type: Conv2D\n",
      "  Output Shape: (None, 7, 7, 320)\n",
      "  Params: 307200\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: block_16_project_BN\n",
      "  Type: BatchNormalization\n",
      "  Output Shape: (None, 7, 7, 320)\n",
      "  Params: 1280\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: Conv_1\n",
      "  Type: Conv2D\n",
      "  Output Shape: (None, 7, 7, 1280)\n",
      "  Params: 409600\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: Conv_1_bn\n",
      "  Type: BatchNormalization\n",
      "  Output Shape: (None, 7, 7, 1280)\n",
      "  Params: 5120\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: out_relu\n",
      "  Type: ReLU\n",
      "  Output Shape: (None, 7, 7, 1280)\n",
      "  Params: 0\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: global_average_pooling2d_13\n",
      "  Type: GlobalAveragePooling2D\n",
      "  Output Shape: (None, 1280)\n",
      "  Params: 0\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: dense_12\n",
      "  Type: Dense\n",
      "  Output Shape: (None, 10)\n",
      "  Params: 12810\n",
      " Trainable: True\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "x = base_model.get_layer(\"out_relu\").output\n",
    "predictions = get_predictions_layer(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "for layer in model.layers[:-1]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compile model\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print('\\nModel architecture:')\n",
    "for layer in model.layers[-20:]:\n",
    "    print(f\"Layer: {layer.name}\")\n",
    "    print(f\"  Type: {layer.__class__.__name__}\")\n",
    "    print(f\"  Output Shape: {layer.output.shape}\")\n",
    "    print(f\"  Params: {layer.count_params()}\")\n",
    "    print(f\" Trainable: {layer.trainable}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "45/45 [==============================] - 14s 278ms/step - loss: 1.6867 - accuracy: 0.4379 - val_loss: 1.2888 - val_accuracy: 0.5616 - lr: 0.0010\n",
      "Epoch 2/30\n",
      "45/45 [==============================] - 12s 260ms/step - loss: 0.8308 - accuracy: 0.7736 - val_loss: 1.0639 - val_accuracy: 0.6046 - lr: 0.0010\n",
      "Epoch 3/30\n",
      "45/45 [==============================] - 12s 255ms/step - loss: 0.6341 - accuracy: 0.8325 - val_loss: 0.8916 - val_accuracy: 0.7020 - lr: 0.0010\n",
      "Epoch 4/30\n",
      "45/45 [==============================] - 12s 261ms/step - loss: 0.5093 - accuracy: 0.8637 - val_loss: 0.8356 - val_accuracy: 0.7278 - lr: 0.0010\n",
      "Epoch 5/30\n",
      "45/45 [==============================] - 12s 257ms/step - loss: 0.4396 - accuracy: 0.8793 - val_loss: 0.7581 - val_accuracy: 0.7479 - lr: 0.0010\n",
      "Epoch 6/30\n",
      "45/45 [==============================] - 12s 267ms/step - loss: 0.3988 - accuracy: 0.8971 - val_loss: 0.6855 - val_accuracy: 0.7708 - lr: 0.0010\n",
      "Epoch 7/30\n",
      "45/45 [==============================] - 12s 257ms/step - loss: 0.3479 - accuracy: 0.9006 - val_loss: 0.6328 - val_accuracy: 0.8052 - lr: 0.0010\n",
      "Epoch 8/30\n",
      "45/45 [==============================] - 12s 260ms/step - loss: 0.3535 - accuracy: 0.8985 - val_loss: 0.6188 - val_accuracy: 0.8109 - lr: 0.0010\n",
      "Epoch 9/30\n",
      "45/45 [==============================] - 12s 257ms/step - loss: 0.3082 - accuracy: 0.9212 - val_loss: 0.5589 - val_accuracy: 0.8281 - lr: 0.0010\n",
      "Epoch 10/30\n",
      "45/45 [==============================] - 12s 261ms/step - loss: 0.2827 - accuracy: 0.9212 - val_loss: 0.5617 - val_accuracy: 0.8109 - lr: 0.0010\n",
      "Epoch 11/30\n",
      "45/45 [==============================] - 12s 265ms/step - loss: 0.2532 - accuracy: 0.9446 - val_loss: 0.5655 - val_accuracy: 0.8138 - lr: 0.0010\n",
      "Epoch 12/30\n",
      "45/45 [==============================] - 12s 271ms/step - loss: 0.2530 - accuracy: 0.9397 - val_loss: 0.5309 - val_accuracy: 0.8395 - lr: 0.0010\n",
      "Epoch 13/30\n",
      "45/45 [==============================] - 11s 254ms/step - loss: 0.2381 - accuracy: 0.9454 - val_loss: 0.5586 - val_accuracy: 0.8223 - lr: 0.0010\n",
      "Epoch 14/30\n",
      "45/45 [==============================] - 12s 263ms/step - loss: 0.2542 - accuracy: 0.9297 - val_loss: 0.5172 - val_accuracy: 0.8338 - lr: 0.0010\n",
      "Epoch 15/30\n",
      "45/45 [==============================] - 11s 255ms/step - loss: 0.2173 - accuracy: 0.9468 - val_loss: 0.5410 - val_accuracy: 0.8281 - lr: 0.0010\n",
      "Epoch 16/30\n",
      "45/45 [==============================] - 12s 261ms/step - loss: 0.2148 - accuracy: 0.9446 - val_loss: 0.4968 - val_accuracy: 0.8281 - lr: 0.0010\n",
      "Epoch 17/30\n",
      "45/45 [==============================] - 12s 256ms/step - loss: 0.1998 - accuracy: 0.9588 - val_loss: 0.5050 - val_accuracy: 0.8338 - lr: 0.0010\n",
      "Epoch 18/30\n",
      "45/45 [==============================] - 12s 267ms/step - loss: 0.1944 - accuracy: 0.9539 - val_loss: 0.5010 - val_accuracy: 0.8367 - lr: 0.0010\n",
      "Epoch 19/30\n",
      "45/45 [==============================] - 12s 255ms/step - loss: 0.1911 - accuracy: 0.9517 - val_loss: 0.4931 - val_accuracy: 0.8453 - lr: 0.0010\n",
      "Epoch 20/30\n",
      "45/45 [==============================] - 12s 260ms/step - loss: 0.1871 - accuracy: 0.9482 - val_loss: 0.4993 - val_accuracy: 0.8166 - lr: 0.0010\n",
      "Epoch 21/30\n",
      "45/45 [==============================] - 12s 255ms/step - loss: 0.1772 - accuracy: 0.9539 - val_loss: 0.4745 - val_accuracy: 0.8453 - lr: 0.0010\n",
      "Epoch 22/30\n",
      "45/45 [==============================] - 12s 260ms/step - loss: 0.1890 - accuracy: 0.9333 - val_loss: 0.4771 - val_accuracy: 0.8309 - lr: 0.0010\n",
      "Epoch 23/30\n",
      "45/45 [==============================] - 12s 255ms/step - loss: 0.1703 - accuracy: 0.9560 - val_loss: 0.4789 - val_accuracy: 0.8453 - lr: 0.0010\n",
      "Epoch 24/30\n",
      "45/45 [==============================] - 12s 266ms/step - loss: 0.1668 - accuracy: 0.9546 - val_loss: 0.4694 - val_accuracy: 0.8453 - lr: 0.0010\n",
      "Epoch 25/30\n",
      "45/45 [==============================] - 11s 253ms/step - loss: 0.1635 - accuracy: 0.9567 - val_loss: 0.4689 - val_accuracy: 0.8481 - lr: 0.0010\n",
      "Epoch 26/30\n",
      "45/45 [==============================] - 12s 262ms/step - loss: 0.1335 - accuracy: 0.9759 - val_loss: 0.4611 - val_accuracy: 0.8453 - lr: 0.0010\n",
      "Epoch 27/30\n",
      "45/45 [==============================] - 11s 254ms/step - loss: 0.1509 - accuracy: 0.9638 - val_loss: 0.4786 - val_accuracy: 0.8453 - lr: 0.0010\n",
      "Epoch 28/30\n",
      "45/45 [==============================] - 12s 261ms/step - loss: 0.1564 - accuracy: 0.9588 - val_loss: 0.4533 - val_accuracy: 0.8539 - lr: 0.0010\n",
      "Epoch 29/30\n",
      "45/45 [==============================] - 12s 257ms/step - loss: 0.1345 - accuracy: 0.9716 - val_loss: 0.4608 - val_accuracy: 0.8453 - lr: 0.0010\n",
      "Epoch 30/30\n",
      "45/45 [==============================] - 12s 262ms/step - loss: 0.1345 - accuracy: 0.9645 - val_loss: 0.4774 - val_accuracy: 0.8338 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=validation_generator,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "model.save(\"mobilenet2.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### V3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not 224. Weights for input shape (224, 224) will be loaded as the default.\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v3/weights_mobilenet_v3_small_224_1.0_float.h5\n",
      "10734624/10734624 [==============================] - 2s 0us/step\n",
      "Layer: re_lu_29\n",
      "  Type: ReLU\n",
      "  Output Shape: (None, None, None, 576)\n",
      "  Params: 0\n",
      "--------------------------------------------------\n",
      "Layer: tf.math.multiply_24\n",
      "  Type: TFOpLambda\n",
      "  Output Shape: (None, None, None, 576)\n",
      "  Params: 0\n",
      "--------------------------------------------------\n",
      "Layer: multiply_16\n",
      "  Type: Multiply\n",
      "  Output Shape: (None, None, None, 576)\n",
      "  Params: 0\n",
      "--------------------------------------------------\n",
      "Layer: expanded_conv_10/squeeze_excite/AvgPool\n",
      "  Type: GlobalAveragePooling2D\n",
      "  Output Shape: (None, 1, 1, 576)\n",
      "  Params: 0\n",
      "--------------------------------------------------\n",
      "Layer: expanded_conv_10/squeeze_excite/Conv\n",
      "  Type: Conv2D\n",
      "  Output Shape: (None, 1, 1, 144)\n",
      "  Params: 83088\n",
      "--------------------------------------------------\n",
      "Layer: expanded_conv_10/squeeze_excite/Relu\n",
      "  Type: ReLU\n",
      "  Output Shape: (None, 1, 1, 144)\n",
      "  Params: 0\n",
      "--------------------------------------------------\n",
      "Layer: expanded_conv_10/squeeze_excite/Conv_1\n",
      "  Type: Conv2D\n",
      "  Output Shape: (None, 1, 1, 576)\n",
      "  Params: 83520\n",
      "--------------------------------------------------\n",
      "Layer: tf.__operators__.add_25\n",
      "  Type: TFOpLambda\n",
      "  Output Shape: (None, 1, 1, 576)\n",
      "  Params: 0\n",
      "--------------------------------------------------\n",
      "Layer: re_lu_30\n",
      "  Type: ReLU\n",
      "  Output Shape: (None, 1, 1, 576)\n",
      "  Params: 0\n",
      "--------------------------------------------------\n",
      "Layer: tf.math.multiply_25\n",
      "  Type: TFOpLambda\n",
      "  Output Shape: (None, 1, 1, 576)\n",
      "  Params: 0\n",
      "--------------------------------------------------\n",
      "Layer: expanded_conv_10/squeeze_excite/Mul\n",
      "  Type: Multiply\n",
      "  Output Shape: (None, None, None, 576)\n",
      "  Params: 0\n",
      "--------------------------------------------------\n",
      "Layer: expanded_conv_10/project\n",
      "  Type: Conv2D\n",
      "  Output Shape: (None, None, None, 96)\n",
      "  Params: 55296\n",
      "--------------------------------------------------\n",
      "Layer: expanded_conv_10/project/BatchNorm\n",
      "  Type: BatchNormalization\n",
      "  Output Shape: (None, None, None, 96)\n",
      "  Params: 384\n",
      "--------------------------------------------------\n",
      "Layer: expanded_conv_10/Add\n",
      "  Type: Add\n",
      "  Output Shape: (None, None, None, 96)\n",
      "  Params: 0\n",
      "--------------------------------------------------\n",
      "Layer: Conv_1\n",
      "  Type: Conv2D\n",
      "  Output Shape: (None, None, None, 576)\n",
      "  Params: 55296\n",
      "--------------------------------------------------\n",
      "Layer: Conv_1/BatchNorm\n",
      "  Type: BatchNormalization\n",
      "  Output Shape: (None, None, None, 576)\n",
      "  Params: 2304\n",
      "--------------------------------------------------\n",
      "Layer: tf.__operators__.add_26\n",
      "  Type: TFOpLambda\n",
      "  Output Shape: (None, None, None, 576)\n",
      "  Params: 0\n",
      "--------------------------------------------------\n",
      "Layer: re_lu_31\n",
      "  Type: ReLU\n",
      "  Output Shape: (None, None, None, 576)\n",
      "  Params: 0\n",
      "--------------------------------------------------\n",
      "Layer: tf.math.multiply_26\n",
      "  Type: TFOpLambda\n",
      "  Output Shape: (None, None, None, 576)\n",
      "  Params: 0\n",
      "--------------------------------------------------\n",
      "Layer: multiply_17\n",
      "  Type: Multiply\n",
      "  Output Shape: (None, None, None, 576)\n",
      "  Params: 0\n",
      "--------------------------------------------------\n",
      "Layer: global_average_pooling2d_4\n",
      "  Type: GlobalAveragePooling2D\n",
      "  Output Shape: (None, 1, 1, 576)\n",
      "  Params: 0\n",
      "--------------------------------------------------\n",
      "Layer: Conv_2\n",
      "  Type: Conv2D\n",
      "  Output Shape: (None, 1, 1, 1024)\n",
      "  Params: 590848\n",
      "--------------------------------------------------\n",
      "Layer: tf.__operators__.add_27\n",
      "  Type: TFOpLambda\n",
      "  Output Shape: (None, 1, 1, 1024)\n",
      "  Params: 0\n",
      "--------------------------------------------------\n",
      "Layer: re_lu_32\n",
      "  Type: ReLU\n",
      "  Output Shape: (None, 1, 1, 1024)\n",
      "  Params: 0\n",
      "--------------------------------------------------\n",
      "Layer: tf.math.multiply_27\n",
      "  Type: TFOpLambda\n",
      "  Output Shape: (None, 1, 1, 1024)\n",
      "  Params: 0\n",
      "--------------------------------------------------\n",
      "Layer: multiply_18\n",
      "  Type: Multiply\n",
      "  Output Shape: (None, 1, 1, 1024)\n",
      "  Params: 0\n",
      "--------------------------------------------------\n",
      "Layer: dropout\n",
      "  Type: Dropout\n",
      "  Output Shape: (None, 1, 1, 1024)\n",
      "  Params: 0\n",
      "--------------------------------------------------\n",
      "Layer: Logits\n",
      "  Type: Conv2D\n",
      "  Output Shape: (None, 1, 1, 1000)\n",
      "  Params: 1025000\n",
      "--------------------------------------------------\n",
      "Layer: flatten\n",
      "  Type: Flatten\n",
      "  Output Shape: (None, 1000)\n",
      "  Params: 0\n",
      "--------------------------------------------------\n",
      "Layer: Predictions\n",
      "  Type: Activation\n",
      "  Output Shape: (None, 1000)\n",
      "  Params: 0\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "base_model = MobileNetV3Small(\n",
    "    include_top=True, \n",
    "    weights='imagenet'\n",
    ")\n",
    "\n",
    "\n",
    "for layer in base_model.layers[-30:]:\n",
    "    print(f\"Layer: {layer.name}\")\n",
    "    print(f\"  Type: {layer.__class__.__name__}\")\n",
    "    print(f\"  Output Shape: {layer.output.shape}\")\n",
    "    print(f\"  Params: {layer.count_params()}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model architecture:\n",
      "Layer: multiply_16\n",
      "  Type: Multiply\n",
      "  Output Shape: (None, None, None, 576)\n",
      "  Params: 0\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: expanded_conv_10/squeeze_excite/AvgPool\n",
      "  Type: GlobalAveragePooling2D\n",
      "  Output Shape: (None, 1, 1, 576)\n",
      "  Params: 0\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: expanded_conv_10/squeeze_excite/Conv\n",
      "  Type: Conv2D\n",
      "  Output Shape: (None, 1, 1, 144)\n",
      "  Params: 83088\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: expanded_conv_10/squeeze_excite/Relu\n",
      "  Type: ReLU\n",
      "  Output Shape: (None, 1, 1, 144)\n",
      "  Params: 0\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: expanded_conv_10/squeeze_excite/Conv_1\n",
      "  Type: Conv2D\n",
      "  Output Shape: (None, 1, 1, 576)\n",
      "  Params: 83520\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: tf.__operators__.add_25\n",
      "  Type: TFOpLambda\n",
      "  Output Shape: (None, 1, 1, 576)\n",
      "  Params: 0\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: re_lu_30\n",
      "  Type: ReLU\n",
      "  Output Shape: (None, 1, 1, 576)\n",
      "  Params: 0\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: tf.math.multiply_25\n",
      "  Type: TFOpLambda\n",
      "  Output Shape: (None, 1, 1, 576)\n",
      "  Params: 0\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: expanded_conv_10/squeeze_excite/Mul\n",
      "  Type: Multiply\n",
      "  Output Shape: (None, None, None, 576)\n",
      "  Params: 0\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: expanded_conv_10/project\n",
      "  Type: Conv2D\n",
      "  Output Shape: (None, None, None, 96)\n",
      "  Params: 55296\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: expanded_conv_10/project/BatchNorm\n",
      "  Type: BatchNormalization\n",
      "  Output Shape: (None, None, None, 96)\n",
      "  Params: 384\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: expanded_conv_10/Add\n",
      "  Type: Add\n",
      "  Output Shape: (None, None, None, 96)\n",
      "  Params: 0\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: Conv_1\n",
      "  Type: Conv2D\n",
      "  Output Shape: (None, None, None, 576)\n",
      "  Params: 55296\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: Conv_1/BatchNorm\n",
      "  Type: BatchNormalization\n",
      "  Output Shape: (None, None, None, 576)\n",
      "  Params: 2304\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: tf.__operators__.add_26\n",
      "  Type: TFOpLambda\n",
      "  Output Shape: (None, None, None, 576)\n",
      "  Params: 0\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: re_lu_31\n",
      "  Type: ReLU\n",
      "  Output Shape: (None, None, None, 576)\n",
      "  Params: 0\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: tf.math.multiply_26\n",
      "  Type: TFOpLambda\n",
      "  Output Shape: (None, None, None, 576)\n",
      "  Params: 0\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: multiply_17\n",
      "  Type: Multiply\n",
      "  Output Shape: (None, None, None, 576)\n",
      "  Params: 0\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: global_average_pooling2d_5\n",
      "  Type: GlobalAveragePooling2D\n",
      "  Output Shape: (None, 576)\n",
      "  Params: 0\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: dense_2\n",
      "  Type: Dense\n",
      "  Output Shape: (None, 10)\n",
      "  Params: 5770\n",
      " Trainable: True\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "x = base_model.get_layer(\"multiply_17\").output\n",
    "predictions = get_predictions_layer(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "for layer in model.layers[:-1]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compile model\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print('\\nModel architecture:')\n",
    "for layer in model.layers[-20:]:\n",
    "    print(f\"Layer: {layer.name}\")\n",
    "    print(f\"  Type: {layer.__class__.__name__}\")\n",
    "    print(f\"  Output Shape: {layer.output.shape}\")\n",
    "    print(f\"  Params: {layer.count_params()}\")\n",
    "    print(f\" Trainable: {layer.trainable}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "45/45 [==============================] - 15s 271ms/step - loss: 2.3191 - accuracy: 0.1086 - val_loss: 2.3113 - val_accuracy: 0.1032 - lr: 0.0010\n",
      "Epoch 2/30\n",
      "45/45 [==============================] - 11s 240ms/step - loss: 2.3053 - accuracy: 0.0965 - val_loss: 2.3159 - val_accuracy: 0.1003 - lr: 0.0010\n",
      "Epoch 3/30\n",
      "45/45 [==============================] - 11s 241ms/step - loss: 2.2995 - accuracy: 0.1128 - val_loss: 2.2939 - val_accuracy: 0.1003 - lr: 0.0010\n",
      "Epoch 4/30\n",
      "45/45 [==============================] - 11s 240ms/step - loss: 2.2964 - accuracy: 0.1143 - val_loss: 2.2915 - val_accuracy: 0.1662 - lr: 0.0010\n",
      "Epoch 5/30\n",
      "45/45 [==============================] - 11s 240ms/step - loss: 2.2864 - accuracy: 0.1171 - val_loss: 2.2885 - val_accuracy: 0.1289 - lr: 0.0010\n",
      "Epoch 6/30\n",
      "45/45 [==============================] - 11s 237ms/step - loss: 2.2755 - accuracy: 0.1363 - val_loss: 2.2820 - val_accuracy: 0.1547 - lr: 0.0010\n",
      "Epoch 7/30\n",
      "45/45 [==============================] - 11s 238ms/step - loss: 2.2648 - accuracy: 0.1675 - val_loss: 2.2849 - val_accuracy: 0.1117 - lr: 0.0010\n",
      "Epoch 8/30\n",
      "45/45 [==============================] - 11s 236ms/step - loss: 2.2632 - accuracy: 0.1498 - val_loss: 2.2730 - val_accuracy: 0.1748 - lr: 0.0010\n",
      "Epoch 9/30\n",
      "45/45 [==============================] - 11s 239ms/step - loss: 2.2471 - accuracy: 0.1930 - val_loss: 2.2793 - val_accuracy: 0.1003 - lr: 0.0010\n",
      "Epoch 10/30\n",
      "45/45 [==============================] - 11s 241ms/step - loss: 2.2491 - accuracy: 0.1547 - val_loss: 2.2668 - val_accuracy: 0.1891 - lr: 0.0010\n",
      "Epoch 11/30\n",
      "45/45 [==============================] - 11s 236ms/step - loss: 2.2399 - accuracy: 0.2257 - val_loss: 2.2859 - val_accuracy: 0.1003 - lr: 0.0010\n",
      "Epoch 12/30\n",
      "45/45 [==============================] - 11s 236ms/step - loss: 2.2352 - accuracy: 0.1881 - val_loss: 2.2602 - val_accuracy: 0.1920 - lr: 0.0010\n",
      "Epoch 13/30\n",
      "45/45 [==============================] - 11s 243ms/step - loss: 2.2221 - accuracy: 0.2605 - val_loss: 2.2636 - val_accuracy: 0.1175 - lr: 0.0010\n",
      "Epoch 14/30\n",
      "45/45 [==============================] - 11s 242ms/step - loss: 2.2201 - accuracy: 0.1831 - val_loss: 2.2597 - val_accuracy: 0.1948 - lr: 0.0010\n",
      "Epoch 15/30\n",
      "45/45 [==============================] - 11s 238ms/step - loss: 2.2089 - accuracy: 0.2129 - val_loss: 2.2583 - val_accuracy: 0.1977 - lr: 0.0010\n",
      "Epoch 16/30\n",
      "45/45 [==============================] - 11s 242ms/step - loss: 2.2146 - accuracy: 0.1781 - val_loss: 2.2543 - val_accuracy: 0.2063 - lr: 0.0010\n",
      "Epoch 17/30\n",
      "45/45 [==============================] - 11s 239ms/step - loss: 2.2046 - accuracy: 0.2314 - val_loss: 2.2551 - val_accuracy: 0.1175 - lr: 0.0010\n",
      "Epoch 18/30\n",
      "45/45 [==============================] - 11s 241ms/step - loss: 2.1998 - accuracy: 0.2200 - val_loss: 2.2477 - val_accuracy: 0.2063 - lr: 0.0010\n",
      "Epoch 19/30\n",
      "45/45 [==============================] - 11s 239ms/step - loss: 2.1905 - accuracy: 0.2541 - val_loss: 2.2454 - val_accuracy: 0.1117 - lr: 0.0010\n",
      "Epoch 20/30\n",
      "45/45 [==============================] - 11s 238ms/step - loss: 2.1926 - accuracy: 0.2143 - val_loss: 2.2437 - val_accuracy: 0.2407 - lr: 0.0010\n",
      "Epoch 21/30\n",
      "45/45 [==============================] - 11s 239ms/step - loss: 2.1802 - accuracy: 0.2633 - val_loss: 2.2545 - val_accuracy: 0.1519 - lr: 0.0010\n",
      "Epoch 22/30\n",
      "45/45 [==============================] - 11s 238ms/step - loss: 2.1764 - accuracy: 0.2285 - val_loss: 2.2337 - val_accuracy: 0.2321 - lr: 0.0010\n",
      "Epoch 23/30\n",
      "45/45 [==============================] - 11s 241ms/step - loss: 2.1521 - accuracy: 0.3258 - val_loss: 2.2335 - val_accuracy: 0.1347 - lr: 0.0010\n",
      "Epoch 24/30\n",
      "45/45 [==============================] - 11s 240ms/step - loss: 2.1611 - accuracy: 0.1895 - val_loss: 2.2297 - val_accuracy: 0.2235 - lr: 0.0010\n",
      "Epoch 25/30\n",
      "45/45 [==============================] - 11s 238ms/step - loss: 2.1550 - accuracy: 0.2768 - val_loss: 2.2386 - val_accuracy: 0.2350 - lr: 0.0010\n",
      "Epoch 26/30\n",
      "45/45 [==============================] - 11s 241ms/step - loss: 2.1494 - accuracy: 0.2590 - val_loss: 2.2197 - val_accuracy: 0.2006 - lr: 0.0010\n",
      "Epoch 27/30\n",
      "45/45 [==============================] - 11s 240ms/step - loss: 2.1414 - accuracy: 0.3130 - val_loss: 2.2483 - val_accuracy: 0.1089 - lr: 0.0010\n",
      "Epoch 28/30\n",
      "45/45 [==============================] - 11s 241ms/step - loss: 2.1406 - accuracy: 0.2477 - val_loss: 2.2152 - val_accuracy: 0.2006 - lr: 0.0010\n",
      "Epoch 29/30\n",
      "45/45 [==============================] - 11s 239ms/step - loss: 2.1400 - accuracy: 0.2747 - val_loss: 2.2121 - val_accuracy: 0.3295 - lr: 0.0010\n",
      "Epoch 30/30\n",
      "45/45 [==============================] - 11s 240ms/step - loss: 2.1322 - accuracy: 0.2690 - val_loss: 2.2218 - val_accuracy: 0.2722 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=validation_generator,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "model.save(\"mobilenet3.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. MobileNetV1 Feature Extraction + XGBoost \n",
    "Using frozen MobileNetV1 as feature extractor for XGBoost classifier\n",
    "### IMPORTANT! Do not shuffle generators before running this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_493804/4125248698.py:2: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  feature_extractor = MobileNet(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: conv_dw_11\n",
      "  Type: DepthwiseConv2D\n",
      "  Output Shape: (None, None, None, 512)\n",
      "  Params: 4608\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: conv_dw_11_bn\n",
      "  Type: BatchNormalization\n",
      "  Output Shape: (None, None, None, 512)\n",
      "  Params: 2048\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: conv_dw_11_relu\n",
      "  Type: ReLU\n",
      "  Output Shape: (None, None, None, 512)\n",
      "  Params: 0\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: conv_pw_11\n",
      "  Type: Conv2D\n",
      "  Output Shape: (None, None, None, 512)\n",
      "  Params: 262144\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: conv_pw_11_bn\n",
      "  Type: BatchNormalization\n",
      "  Output Shape: (None, None, None, 512)\n",
      "  Params: 2048\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: conv_pw_11_relu\n",
      "  Type: ReLU\n",
      "  Output Shape: (None, None, None, 512)\n",
      "  Params: 0\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: conv_pad_12\n",
      "  Type: ZeroPadding2D\n",
      "  Output Shape: (None, None, None, 512)\n",
      "  Params: 0\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: conv_dw_12\n",
      "  Type: DepthwiseConv2D\n",
      "  Output Shape: (None, None, None, 512)\n",
      "  Params: 4608\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: conv_dw_12_bn\n",
      "  Type: BatchNormalization\n",
      "  Output Shape: (None, None, None, 512)\n",
      "  Params: 2048\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: conv_dw_12_relu\n",
      "  Type: ReLU\n",
      "  Output Shape: (None, None, None, 512)\n",
      "  Params: 0\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: conv_pw_12\n",
      "  Type: Conv2D\n",
      "  Output Shape: (None, None, None, 1024)\n",
      "  Params: 524288\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: conv_pw_12_bn\n",
      "  Type: BatchNormalization\n",
      "  Output Shape: (None, None, None, 1024)\n",
      "  Params: 4096\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: conv_pw_12_relu\n",
      "  Type: ReLU\n",
      "  Output Shape: (None, None, None, 1024)\n",
      "  Params: 0\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: conv_dw_13\n",
      "  Type: DepthwiseConv2D\n",
      "  Output Shape: (None, None, None, 1024)\n",
      "  Params: 9216\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: conv_dw_13_bn\n",
      "  Type: BatchNormalization\n",
      "  Output Shape: (None, None, None, 1024)\n",
      "  Params: 4096\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: conv_dw_13_relu\n",
      "  Type: ReLU\n",
      "  Output Shape: (None, None, None, 1024)\n",
      "  Params: 0\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: conv_pw_13\n",
      "  Type: Conv2D\n",
      "  Output Shape: (None, None, None, 1024)\n",
      "  Params: 1048576\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: conv_pw_13_bn\n",
      "  Type: BatchNormalization\n",
      "  Output Shape: (None, None, None, 1024)\n",
      "  Params: 4096\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: conv_pw_13_relu\n",
      "  Type: ReLU\n",
      "  Output Shape: (None, None, None, 1024)\n",
      "  Params: 0\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: global_average_pooling2d_3\n",
      "  Type: GlobalAveragePooling2D\n",
      "  Output Shape: (None, 1024)\n",
      "  Params: 0\n",
      " Trainable: False\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Load MobileNetV1 without head and freeze it\n",
    "feature_extractor = MobileNet(\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    pooling='avg'\n",
    ")\n",
    "\n",
    "# Freeze all layers\n",
    "feature_extractor.trainable = False\n",
    "\n",
    "# feature_extractor.summary()\n",
    "\n",
    "for layer in feature_extractor.layers[-20:]:\n",
    "    print(f\"Layer: {layer.name}\")\n",
    "    print(f\"  Type: {layer.__class__.__name__}\")\n",
    "    print(f\"  Output Shape: {layer.output.shape}\")\n",
    "    print(f\"  Params: {layer.count_params()}\")\n",
    "    print(f\" Trainable: {layer.trainable}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting training features...\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 450ms/step\n",
      "\n",
      "Extracting validation features...\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 344ms/step\n",
      "\n",
      "Feature shapes:\n",
      "X_train: (1409, 1024)\n",
      "X_val: (349, 1024)\n",
      "y_train: (1409,)\n",
      "y_val: (349,)\n"
     ]
    }
   ],
   "source": [
    "# Extract features from training and validation data\n",
    "print('Extracting training features...')\n",
    "X_train = feature_extractor.predict(train_generator, verbose=1)\n",
    "y_train = train_generator.classes\n",
    "\n",
    "print(f'\\nExtracting validation features...')\n",
    "X_val = feature_extractor.predict(validation_generator, verbose=1)\n",
    "y_val = validation_generator.classes\n",
    "\n",
    "print(f'\\nFeature shapes:')\n",
    "print(f'X_train: {X_train.shape}')\n",
    "print(f'X_val: {X_val.shape}')\n",
    "print(f'y_train: {y_train.shape}')\n",
    "print(f'y_val: {y_val.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.1545032 , 0.        , 0.9261188 , ..., 0.67607176, 0.2801631 ,\n",
       "        1.4572111 ],\n",
       "       [0.09016517, 0.        , 2.0843697 , ..., 1.6000296 , 0.26056516,\n",
       "        1.3161356 ],\n",
       "       [0.29053462, 0.        , 1.3169994 , ..., 2.1586185 , 0.09628654,\n",
       "        0.83240616],\n",
       "       ...,\n",
       "       [1.9129909 , 0.07743069, 2.4824505 , ..., 1.0810454 , 0.2585196 ,\n",
       "        2.1517427 ],\n",
       "       [1.11826   , 0.01619181, 2.0798414 , ..., 1.7273229 , 0.39629543,\n",
       "        1.4504533 ],\n",
       "       [1.3605657 , 0.        , 2.4364338 , ..., 1.6396586 , 0.31785315,\n",
       "        1.0187277 ]], shape=(349, 1024), dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "       6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "       6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
       "       7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8,\n",
       "       8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
       "       8, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
       "       9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training XGBoost...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "}\n",
       "\n",
       "#sk-container-id-1.light {\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: black;\n",
       "  --sklearn-color-background: white;\n",
       "  --sklearn-color-border-box: black;\n",
       "  --sklearn-color-icon: #696969;\n",
       "}\n",
       "\n",
       "#sk-container-id-1.dark {\n",
       "  --sklearn-color-text-on-default-background: white;\n",
       "  --sklearn-color-background: #111;\n",
       "  --sklearn-color-border-box: white;\n",
       "  --sklearn-color-icon: #878787;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: center;\n",
       "  justify-content: center;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table {\n",
       "    font-family: monospace;\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table summary::marker {\n",
       "    font-size: 0.7rem;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "    margin-top: 0;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       "/*\n",
       "    `table td`is set in notebook with right text-align.\n",
       "    We need to overwrite it.\n",
       "*/\n",
       ".estimator-table table td.param {\n",
       "    text-align: left;\n",
       "    position: relative;\n",
       "    padding: 0;\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td.value {\n",
       "    color:rgb(255, 94, 0);\n",
       "    background-color: transparent;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       "/*\n",
       "    Styles for parameter documentation links\n",
       "    We need styling for visited so jupyter doesn't overwrite it\n",
       "*/\n",
       "a.param-doc-link,\n",
       "a.param-doc-link:link,\n",
       "a.param-doc-link:visited {\n",
       "    text-decoration: underline dashed;\n",
       "    text-underline-offset: .3em;\n",
       "    color: inherit;\n",
       "    display: block;\n",
       "    padding: .5em;\n",
       "}\n",
       "\n",
       "/* \"hack\" to make the entire area of the cell containing the link clickable */\n",
       "a.param-doc-link::before {\n",
       "    position: absolute;\n",
       "    content: \"\";\n",
       "    inset: 0;\n",
       "}\n",
       "\n",
       ".param-doc-description {\n",
       "    display: none;\n",
       "    position: absolute;\n",
       "    z-index: 9999;\n",
       "    left: 0;\n",
       "    padding: .5ex;\n",
       "    margin-left: 1.5em;\n",
       "    color: var(--sklearn-color-text);\n",
       "    box-shadow: .3em .3em .4em #999;\n",
       "    width: max-content;\n",
       "    text-align: left;\n",
       "    max-height: 10em;\n",
       "    overflow-y: auto;\n",
       "\n",
       "    /* unfitted */\n",
       "    background: var(--sklearn-color-unfitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       "/* Fitted state for parameter tooltips */\n",
       ".fitted .param-doc-description {\n",
       "    /* fitted */\n",
       "    background: var(--sklearn-color-fitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".param-doc-link:hover .param-doc-description {\n",
       "    display: block;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              feature_weights=None, gamma=0.1, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=0.05, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=8,\n",
       "              max_leaves=None, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=300,\n",
       "              n_jobs=None, num_parallel_tree=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>XGBClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier\">?<span>Documentation for XGBClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('objective',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=objective,-typing.Union%5Bstr%2C%20xgboost.sklearn._SklObjWProto%2C%20typing.Callable%5B%5Btyping.Any%2C%20typing.Any%5D%2C%20typing.Tuple%5Bnumpy.ndarray%2C%20numpy.ndarray%5D%5D%2C%20NoneType%5D\">\n",
       "            objective\n",
       "            <span class=\"param-doc-description\">objective: typing.Union[str, xgboost.sklearn._SklObjWProto, typing.Callable[[typing.Any, typing.Any], typing.Tuple[numpy.ndarray, numpy.ndarray]], NoneType]<br><br>Specify the learning task and the corresponding learning objective or a custom<br>objective function to be used.<br><br>For custom objective, see :doc:`/tutorials/custom_metric_obj` and<br>:ref:`custom-obj-metric` for more information, along with the end note for<br>function signatures.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;multi:softprob&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('base_score',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=base_score,-typing.Union%5Bfloat%2C%20typing.List%5Bfloat%5D%2C%20NoneType%5D\">\n",
       "            base_score\n",
       "            <span class=\"param-doc-description\">base_score: typing.Union[float, typing.List[float], NoneType]<br><br>The initial prediction score of all instances, global bias.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('booster',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">booster</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('callbacks',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=callbacks,-typing.Optional%5Btyping.List%5Bxgboost.callback.TrainingCallback%5D%5D\">\n",
       "            callbacks\n",
       "            <span class=\"param-doc-description\">callbacks: typing.Optional[typing.List[xgboost.callback.TrainingCallback]]<br><br>List of callback functions that are applied at end of each iteration.<br>It is possible to use predefined callbacks by using<br>:ref:`Callback API <callback_api>`.<br><br>.. note::<br><br>   States in callback are not preserved during training, which means callback<br>   objects can not be reused for multiple training sessions without<br>   reinitialization or deepcopy.<br><br>.. code-block:: python<br><br>    for params in parameters_grid:<br>        # be sure to (re)initialize the callbacks before each run<br>        callbacks = [xgb.callback.LearningRateScheduler(custom_rates)]<br>        reg = xgboost.XGBRegressor(**params, callbacks=callbacks)<br>        reg.fit(X, y)</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('colsample_bylevel',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=colsample_bylevel,-typing.Optional%5Bfloat%5D\">\n",
       "            colsample_bylevel\n",
       "            <span class=\"param-doc-description\">colsample_bylevel: typing.Optional[float]<br><br>Subsample ratio of columns for each level.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('colsample_bynode',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=colsample_bynode,-typing.Optional%5Bfloat%5D\">\n",
       "            colsample_bynode\n",
       "            <span class=\"param-doc-description\">colsample_bynode: typing.Optional[float]<br><br>Subsample ratio of columns for each split.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('colsample_bytree',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=colsample_bytree,-typing.Optional%5Bfloat%5D\">\n",
       "            colsample_bytree\n",
       "            <span class=\"param-doc-description\">colsample_bytree: typing.Optional[float]<br><br>Subsample ratio of columns when constructing each tree.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.8</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('device',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=device,-typing.Optional%5Bstr%5D\">\n",
       "            device\n",
       "            <span class=\"param-doc-description\">device: typing.Optional[str]<br><br>.. versionadded:: 2.0.0<br><br>Device ordinal, available options are `cpu`, `cuda`, and `gpu`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('early_stopping_rounds',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=early_stopping_rounds,-typing.Optional%5Bint%5D\">\n",
       "            early_stopping_rounds\n",
       "            <span class=\"param-doc-description\">early_stopping_rounds: typing.Optional[int]<br><br>.. versionadded:: 1.6.0<br><br>- Activates early stopping. Validation metric needs to improve at least once in<br>  every **early_stopping_rounds** round(s) to continue training.  Requires at<br>  least one item in **eval_set** in :py:meth:`fit`.<br><br>- If early stopping occurs, the model will have two additional attributes:<br>  :py:attr:`best_score` and :py:attr:`best_iteration`. These are used by the<br>  :py:meth:`predict` and :py:meth:`apply` methods to determine the optimal<br>  number of trees during inference. If users want to access the full model<br>  (including trees built after early stopping), they can specify the<br>  `iteration_range` in these inference methods. In addition, other utilities<br>  like model plotting can also use the entire model.<br><br>- If you prefer to discard the trees after `best_iteration`, consider using the<br>  callback function :py:class:`xgboost.callback.EarlyStopping`.<br><br>- If there's more than one item in **eval_set**, the last entry will be used for<br>  early stopping.  If there's more than one metric in **eval_metric**, the last<br>  metric will be used for early stopping.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('enable_categorical',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=enable_categorical,-bool\">\n",
       "            enable_categorical\n",
       "            <span class=\"param-doc-description\">enable_categorical: bool<br><br>See the same parameter of :py:class:`DMatrix` for details.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('eval_metric',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=eval_metric,-typing.Union%5Bstr%2C%20typing.List%5Btyping.Union%5Bstr%2C%20typing.Callable%5D%5D%2C%20typing.Callable%2C%20NoneType%5D\">\n",
       "            eval_metric\n",
       "            <span class=\"param-doc-description\">eval_metric: typing.Union[str, typing.List[typing.Union[str, typing.Callable]], typing.Callable, NoneType]<br><br>.. versionadded:: 1.6.0<br><br>Metric used for monitoring the training result and early stopping.  It can be a<br>string or list of strings as names of predefined metric in XGBoost (See<br>:doc:`/parameter`), one of the metrics in :py:mod:`sklearn.metrics`, or any<br>other user defined metric that looks like `sklearn.metrics`.<br><br>If custom objective is also provided, then custom metric should implement the<br>corresponding reverse link function.<br><br>Unlike the `scoring` parameter commonly used in scikit-learn, when a callable<br>object is provided, it's assumed to be a cost function and by default XGBoost<br>will minimize the result during early stopping.<br><br>For advanced usage on Early stopping like directly choosing to maximize instead<br>of minimize, see :py:obj:`xgboost.callback.EarlyStopping`.<br><br>See :doc:`/tutorials/custom_metric_obj` and :ref:`custom-obj-metric` for more<br>information.<br><br>.. code-block:: python<br><br>    from sklearn.datasets import load_diabetes<br>    from sklearn.metrics import mean_absolute_error<br>    X, y = load_diabetes(return_X_y=True)<br>    reg = xgb.XGBRegressor(<br>        tree_method=\"hist\",<br>        eval_metric=mean_absolute_error,<br>    )<br>    reg.fit(X, y, eval_set=[(X, y)])</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('feature_types',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=feature_types,-typing.Optional%5Btyping.Sequence%5Bstr%5D%5D\">\n",
       "            feature_types\n",
       "            <span class=\"param-doc-description\">feature_types: typing.Optional[typing.Sequence[str]]<br><br>.. versionadded:: 1.7.0<br><br>Used for specifying feature types without constructing a dataframe. See<br>the :py:class:`DMatrix` for details.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('feature_weights',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=feature_weights,-Optional%5BArrayLike%5D\">\n",
       "            feature_weights\n",
       "            <span class=\"param-doc-description\">feature_weights: Optional[ArrayLike]<br><br>Weight for each feature, defines the probability of each feature being selected<br>when colsample is being used.  All values must be greater than 0, otherwise a<br>`ValueError` is thrown.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('gamma',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=gamma,-typing.Optional%5Bfloat%5D\">\n",
       "            gamma\n",
       "            <span class=\"param-doc-description\">gamma: typing.Optional[float]<br><br>(min_split_loss) Minimum loss reduction required to make a further partition on<br>a leaf node of the tree.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('grow_policy',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=grow_policy,-typing.Optional%5Bstr%5D\">\n",
       "            grow_policy\n",
       "            <span class=\"param-doc-description\">grow_policy: typing.Optional[str]<br><br>Tree growing policy.<br><br>- depthwise: Favors splitting at nodes closest to the node,<br>- lossguide: Favors splitting at nodes with highest loss change.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('importance_type',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">importance_type</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('interaction_constraints',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=interaction_constraints,-typing.Union%5Bstr%2C%20typing.List%5Btyping.Tuple%5Bstr%5D%5D%2C%20NoneType%5D\">\n",
       "            interaction_constraints\n",
       "            <span class=\"param-doc-description\">interaction_constraints: typing.Union[str, typing.List[typing.Tuple[str]], NoneType]<br><br>Constraints for interaction representing permitted interactions.  The<br>constraints must be specified in the form of a nested list, e.g. ``[[0, 1], [2,<br>3, 4]]``, where each inner list is a group of indices of features that are<br>allowed to interact with each other.  See :doc:`tutorial<br></tutorials/feature_interaction_constraint>` for more information</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('learning_rate',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=learning_rate,-typing.Optional%5Bfloat%5D\">\n",
       "            learning_rate\n",
       "            <span class=\"param-doc-description\">learning_rate: typing.Optional[float]<br><br>Boosting learning rate (xgb's \"eta\")</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.05</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_bin',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=max_bin,-typing.Optional%5Bint%5D\">\n",
       "            max_bin\n",
       "            <span class=\"param-doc-description\">max_bin: typing.Optional[int]<br><br>If using histogram-based algorithm, maximum number of bins per feature</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_cat_threshold',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=max_cat_threshold,-typing.Optional%5Bint%5D\">\n",
       "            max_cat_threshold\n",
       "            <span class=\"param-doc-description\">max_cat_threshold: typing.Optional[int]<br><br>.. versionadded:: 1.7.0<br><br>.. note:: This parameter is experimental<br><br>Maximum number of categories considered for each split. Used only by<br>partition-based splits for preventing over-fitting. Also, `enable_categorical`<br>needs to be set to have categorical feature support. See :doc:`Categorical Data<br></tutorials/categorical>` and :ref:`cat-param` for details.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_cat_to_onehot',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=max_cat_to_onehot,-Optional%5Bint%5D\">\n",
       "            max_cat_to_onehot\n",
       "            <span class=\"param-doc-description\">max_cat_to_onehot: Optional[int]<br><br>.. versionadded:: 1.6.0<br><br>.. note:: This parameter is experimental<br><br>A threshold for deciding whether XGBoost should use one-hot encoding based split<br>for categorical data.  When number of categories is lesser than the threshold<br>then one-hot encoding is chosen, otherwise the categories will be partitioned<br>into children nodes. Also, `enable_categorical` needs to be set to have<br>categorical feature support. See :doc:`Categorical Data<br></tutorials/categorical>` and :ref:`cat-param` for details.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_delta_step',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=max_delta_step,-typing.Optional%5Bfloat%5D\">\n",
       "            max_delta_step\n",
       "            <span class=\"param-doc-description\">max_delta_step: typing.Optional[float]<br><br>Maximum delta step we allow each tree's weight estimation to be.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_depth',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=max_depth,-%20typing.Optional%5Bint%5D\">\n",
       "            max_depth\n",
       "            <span class=\"param-doc-description\">max_depth:  typing.Optional[int]<br><br>Maximum tree depth for base learners.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">8</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_leaves',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=max_leaves,-typing.Optional%5Bint%5D\">\n",
       "            max_leaves\n",
       "            <span class=\"param-doc-description\">max_leaves: typing.Optional[int]<br><br>Maximum number of leaves; 0 indicates no limit.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_child_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=min_child_weight,-typing.Optional%5Bfloat%5D\">\n",
       "            min_child_weight\n",
       "            <span class=\"param-doc-description\">min_child_weight: typing.Optional[float]<br><br>Minimum sum of instance weight(hessian) needed in a child.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('missing',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=missing,-float\">\n",
       "            missing\n",
       "            <span class=\"param-doc-description\">missing: float<br><br>Value in the data which needs to be present as a missing value. Default to<br>:py:data:`numpy.nan`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">nan</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('monotone_constraints',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=monotone_constraints,-typing.Union%5Btyping.Dict%5Bstr%2C%20int%5D%2C%20str%2C%20NoneType%5D\">\n",
       "            monotone_constraints\n",
       "            <span class=\"param-doc-description\">monotone_constraints: typing.Union[typing.Dict[str, int], str, NoneType]<br><br>Constraint of variable monotonicity.  See :doc:`tutorial </tutorials/monotonic>`<br>for more information.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('multi_strategy',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=multi_strategy,-typing.Optional%5Bstr%5D\">\n",
       "            multi_strategy\n",
       "            <span class=\"param-doc-description\">multi_strategy: typing.Optional[str]<br><br>.. versionadded:: 2.0.0<br><br>.. note:: This parameter is working-in-progress.<br><br>The strategy used for training multi-target models, including multi-target<br>regression and multi-class classification. See :doc:`/tutorials/multioutput` for<br>more information.<br><br>- ``one_output_per_tree``: One model for each target.<br>- ``multi_output_tree``:  Use multi-target trees.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_estimators',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=n_estimators,-Optional%5Bint%5D\">\n",
       "            n_estimators\n",
       "            <span class=\"param-doc-description\">n_estimators: Optional[int]<br><br>Number of boosting rounds.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">300</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=n_jobs,-typing.Optional%5Bint%5D\">\n",
       "            n_jobs\n",
       "            <span class=\"param-doc-description\">n_jobs: typing.Optional[int]<br><br>Number of parallel threads used to run xgboost.  When used with other<br>Scikit-Learn algorithms like grid search, you may choose which algorithm to<br>parallelize and balance the threads.  Creating thread contention will<br>significantly slow down both algorithms.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('num_parallel_tree',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">num_parallel_tree</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=random_state,-typing.Union%5Bnumpy.random.mtrand.RandomState%2C%20numpy.random._generator.Generator%2C%20int%2C%20NoneType%5D\">\n",
       "            random_state\n",
       "            <span class=\"param-doc-description\">random_state: typing.Union[numpy.random.mtrand.RandomState, numpy.random._generator.Generator, int, NoneType]<br><br>Random number seed.<br><br>.. note::<br><br>   Using gblinear booster with shotgun updater is nondeterministic as<br>   it uses Hogwild algorithm.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">42</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('reg_alpha',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=reg_alpha,-typing.Optional%5Bfloat%5D\">\n",
       "            reg_alpha\n",
       "            <span class=\"param-doc-description\">reg_alpha: typing.Optional[float]<br><br>L1 regularization term on weights (xgb's alpha).</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.01</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('reg_lambda',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=reg_lambda,-typing.Optional%5Bfloat%5D\">\n",
       "            reg_lambda\n",
       "            <span class=\"param-doc-description\">reg_lambda: typing.Optional[float]<br><br>L2 regularization term on weights (xgb's lambda).</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">1.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('sampling_method',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=sampling_method,-typing.Optional%5Bstr%5D\">\n",
       "            sampling_method\n",
       "            <span class=\"param-doc-description\">sampling_method: typing.Optional[str]<br><br>Sampling method. Used only by the GPU version of ``hist`` tree method.<br><br>- ``uniform``: Select random training instances uniformly.<br>- ``gradient_based``: Select random training instances with higher probability<br>    when the gradient and hessian are larger. (cf. CatBoost)</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('scale_pos_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=scale_pos_weight,-typing.Optional%5Bfloat%5D\">\n",
       "            scale_pos_weight\n",
       "            <span class=\"param-doc-description\">scale_pos_weight: typing.Optional[float]<br><br>Balancing of positive and negative weights.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('subsample',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=subsample,-typing.Optional%5Bfloat%5D\">\n",
       "            subsample\n",
       "            <span class=\"param-doc-description\">subsample: typing.Optional[float]<br><br>Subsample ratio of the training instance.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.8</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tree_method',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=tree_method,-typing.Optional%5Bstr%5D\">\n",
       "            tree_method\n",
       "            <span class=\"param-doc-description\">tree_method: typing.Optional[str]<br><br>Specify which tree method to use.  Default to auto.  If this parameter is set to<br>default, XGBoost will choose the most conservative option available.  It's<br>recommended to study this option from the parameters document :doc:`tree method<br></treemethod>`</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('validate_parameters',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=validate_parameters,-typing.Optional%5Bbool%5D\">\n",
       "            validate_parameters\n",
       "            <span class=\"param-doc-description\">validate_parameters: typing.Optional[bool]<br><br>Give warnings for unknown parameter.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbosity',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=verbosity,-typing.Optional%5Bint%5D\">\n",
       "            verbosity\n",
       "            <span class=\"param-doc-description\">verbosity: typing.Optional[int]<br><br>The degree of verbosity. Valid values are 0 (silent) - 3 (debug).</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.copy-paste-icon').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling\n",
       "        .textContent.trim().split(' ')[0];\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "\n",
       "\n",
       "/**\n",
       " * Adapted from Skrub\n",
       " * https://github.com/skrub-data/skrub/blob/403466d1d5d4dc76a7ef569b3f8228db59a31dc3/skrub/_reporting/_data/templates/report.js#L789\n",
       " * @returns \"light\" or \"dark\"\n",
       " */\n",
       "function detectTheme(element) {\n",
       "    const body = document.querySelector('body');\n",
       "\n",
       "    // Check VSCode theme\n",
       "    const themeKindAttr = body.getAttribute('data-vscode-theme-kind');\n",
       "    const themeNameAttr = body.getAttribute('data-vscode-theme-name');\n",
       "\n",
       "    if (themeKindAttr && themeNameAttr) {\n",
       "        const themeKind = themeKindAttr.toLowerCase();\n",
       "        const themeName = themeNameAttr.toLowerCase();\n",
       "\n",
       "        if (themeKind.includes(\"dark\") || themeName.includes(\"dark\")) {\n",
       "            return \"dark\";\n",
       "        }\n",
       "        if (themeKind.includes(\"light\") || themeName.includes(\"light\")) {\n",
       "            return \"light\";\n",
       "        }\n",
       "    }\n",
       "\n",
       "    // Check Jupyter theme\n",
       "    if (body.getAttribute('data-jp-theme-light') === 'false') {\n",
       "        return 'dark';\n",
       "    } else if (body.getAttribute('data-jp-theme-light') === 'true') {\n",
       "        return 'light';\n",
       "    }\n",
       "\n",
       "    // Guess based on a parent element's color\n",
       "    const color = window.getComputedStyle(element.parentNode, null).getPropertyValue('color');\n",
       "    const match = color.match(/^rgb\\s*\\(\\s*(\\d+)\\s*,\\s*(\\d+)\\s*,\\s*(\\d+)\\s*\\)\\s*$/i);\n",
       "    if (match) {\n",
       "        const [r, g, b] = [\n",
       "            parseFloat(match[1]),\n",
       "            parseFloat(match[2]),\n",
       "            parseFloat(match[3])\n",
       "        ];\n",
       "\n",
       "        // https://en.wikipedia.org/wiki/HSL_and_HSV#Lightness\n",
       "        const luma = 0.299 * r + 0.587 * g + 0.114 * b;\n",
       "\n",
       "        if (luma > 180) {\n",
       "            // If the text is very bright we have a dark theme\n",
       "            return 'dark';\n",
       "        }\n",
       "        if (luma < 75) {\n",
       "            // If the text is very dark we have a light theme\n",
       "            return 'light';\n",
       "        }\n",
       "        // Otherwise fall back to the next heuristic.\n",
       "    }\n",
       "\n",
       "    // Fallback to system preference\n",
       "    return window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light';\n",
       "}\n",
       "\n",
       "\n",
       "function forceTheme(elementId) {\n",
       "    const estimatorElement = document.querySelector(`#${elementId}`);\n",
       "    if (estimatorElement === null) {\n",
       "        console.error(`Element with id ${elementId} not found.`);\n",
       "    } else {\n",
       "        const theme = detectTheme(estimatorElement);\n",
       "        estimatorElement.classList.add(theme);\n",
       "    }\n",
       "}\n",
       "\n",
       "forceTheme('sk-container-id-1');</script></body>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              feature_weights=None, gamma=0.1, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=0.05, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=8,\n",
       "              max_leaves=None, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=300,\n",
       "              n_jobs=None, num_parallel_tree=None, ...)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train XGBoost classifier with tuned parameters\n",
    "xgb_model = XGBClassifier(\n",
    "    random_state=42,\n",
    "    n_estimators=300,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=8,\n",
    "    min_child_weight=1,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    gamma=0.1,\n",
    "    reg_alpha=0.01,\n",
    "    reg_lambda=1.0\n",
    ")\n",
    "\n",
    "print('Training XGBoost...')\n",
    "xgb_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Accuracy: 0.8138 (81.38%)\n"
     ]
    }
   ],
   "source": [
    "# Evaluate XGBoost on validation set\n",
    "y_pred = xgb_model.predict(X_val)\n",
    "accuracy = (y_pred == y_val).mean()\n",
    "\n",
    "print(f'\\nValidation Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RandomForest...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "}\n",
       "\n",
       "#sk-container-id-4.light {\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: black;\n",
       "  --sklearn-color-background: white;\n",
       "  --sklearn-color-border-box: black;\n",
       "  --sklearn-color-icon: #696969;\n",
       "}\n",
       "\n",
       "#sk-container-id-4.dark {\n",
       "  --sklearn-color-text-on-default-background: white;\n",
       "  --sklearn-color-background: #111;\n",
       "  --sklearn-color-border-box: white;\n",
       "  --sklearn-color-icon: #878787;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-4 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: center;\n",
       "  justify-content: center;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-4 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-4 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-4 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-4 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table {\n",
       "    font-family: monospace;\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table summary::marker {\n",
       "    font-size: 0.7rem;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "    margin-top: 0;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       "/*\n",
       "    `table td`is set in notebook with right text-align.\n",
       "    We need to overwrite it.\n",
       "*/\n",
       ".estimator-table table td.param {\n",
       "    text-align: left;\n",
       "    position: relative;\n",
       "    padding: 0;\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td.value {\n",
       "    color:rgb(255, 94, 0);\n",
       "    background-color: transparent;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       "/*\n",
       "    Styles for parameter documentation links\n",
       "    We need styling for visited so jupyter doesn't overwrite it\n",
       "*/\n",
       "a.param-doc-link,\n",
       "a.param-doc-link:link,\n",
       "a.param-doc-link:visited {\n",
       "    text-decoration: underline dashed;\n",
       "    text-underline-offset: .3em;\n",
       "    color: inherit;\n",
       "    display: block;\n",
       "    padding: .5em;\n",
       "}\n",
       "\n",
       "/* \"hack\" to make the entire area of the cell containing the link clickable */\n",
       "a.param-doc-link::before {\n",
       "    position: absolute;\n",
       "    content: \"\";\n",
       "    inset: 0;\n",
       "}\n",
       "\n",
       ".param-doc-description {\n",
       "    display: none;\n",
       "    position: absolute;\n",
       "    z-index: 9999;\n",
       "    left: 0;\n",
       "    padding: .5ex;\n",
       "    margin-left: 1.5em;\n",
       "    color: var(--sklearn-color-text);\n",
       "    box-shadow: .3em .3em .4em #999;\n",
       "    width: max-content;\n",
       "    text-align: left;\n",
       "    max-height: 10em;\n",
       "    overflow-y: auto;\n",
       "\n",
       "    /* unfitted */\n",
       "    background: var(--sklearn-color-unfitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       "/* Fitted state for parameter tooltips */\n",
       ".fitted .param-doc-description {\n",
       "    /* fitted */\n",
       "    background: var(--sklearn-color-fitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".param-doc-link:hover .param-doc-description {\n",
       "    display: block;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>RandomForestClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_estimators',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=n_estimators,-int%2C%20default%3D100\">\n",
       "            n_estimators\n",
       "            <span class=\"param-doc-description\">n_estimators: int, default=100<br><br>The number of trees in the forest.<br><br>.. versionchanged:: 0.22<br>   The default value of ``n_estimators`` changed from 10 to 100<br>   in 0.22.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">100</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('criterion',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=criterion,-%7B%22gini%22%2C%20%22entropy%22%2C%20%22log_loss%22%7D%2C%20default%3D%22gini%22\">\n",
       "            criterion\n",
       "            <span class=\"param-doc-description\">criterion: {\"gini\", \"entropy\", \"log_loss\"}, default=\"gini\"<br><br>The function to measure the quality of a split. Supported criteria are<br>\"gini\" for the Gini impurity and \"log_loss\" and \"entropy\" both for the<br>Shannon information gain, see :ref:`tree_mathematical_formulation`.<br>Note: This parameter is tree-specific.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;gini&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_depth',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=max_depth,-int%2C%20default%3DNone\">\n",
       "            max_depth\n",
       "            <span class=\"param-doc-description\">max_depth: int, default=None<br><br>The maximum depth of the tree. If None, then nodes are expanded until<br>all leaves are pure or until all leaves contain less than<br>min_samples_split samples.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_samples_split',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=min_samples_split,-int%20or%20float%2C%20default%3D2\">\n",
       "            min_samples_split\n",
       "            <span class=\"param-doc-description\">min_samples_split: int or float, default=2<br><br>The minimum number of samples required to split an internal node:<br><br>- If int, then consider `min_samples_split` as the minimum number.<br>- If float, then `min_samples_split` is a fraction and<br>  `ceil(min_samples_split * n_samples)` are the minimum<br>  number of samples for each split.<br><br>.. versionchanged:: 0.18<br>   Added float values for fractions.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">2</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_samples_leaf',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=min_samples_leaf,-int%20or%20float%2C%20default%3D1\">\n",
       "            min_samples_leaf\n",
       "            <span class=\"param-doc-description\">min_samples_leaf: int or float, default=1<br><br>The minimum number of samples required to be at a leaf node.<br>A split point at any depth will only be considered if it leaves at<br>least ``min_samples_leaf`` training samples in each of the left and<br>right branches.  This may have the effect of smoothing the model,<br>especially in regression.<br><br>- If int, then consider `min_samples_leaf` as the minimum number.<br>- If float, then `min_samples_leaf` is a fraction and<br>  `ceil(min_samples_leaf * n_samples)` are the minimum<br>  number of samples for each node.<br><br>.. versionchanged:: 0.18<br>   Added float values for fractions.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_weight_fraction_leaf',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=min_weight_fraction_leaf,-float%2C%20default%3D0.0\">\n",
       "            min_weight_fraction_leaf\n",
       "            <span class=\"param-doc-description\">min_weight_fraction_leaf: float, default=0.0<br><br>The minimum weighted fraction of the sum total of weights (of all<br>the input samples) required to be at a leaf node. Samples have<br>equal weight when sample_weight is not provided.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_features',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=max_features,-%7B%22sqrt%22%2C%20%22log2%22%2C%20None%7D%2C%20int%20or%20float%2C%20default%3D%22sqrt%22\">\n",
       "            max_features\n",
       "            <span class=\"param-doc-description\">max_features: {\"sqrt\", \"log2\", None}, int or float, default=\"sqrt\"<br><br>The number of features to consider when looking for the best split:<br><br>- If int, then consider `max_features` features at each split.<br>- If float, then `max_features` is a fraction and<br>  `max(1, int(max_features * n_features_in_))` features are considered at each<br>  split.<br>- If \"sqrt\", then `max_features=sqrt(n_features)`.<br>- If \"log2\", then `max_features=log2(n_features)`.<br>- If None, then `max_features=n_features`.<br><br>.. versionchanged:: 1.1<br>    The default of `max_features` changed from `\"auto\"` to `\"sqrt\"`.<br><br>Note: the search for a split does not stop until at least one<br>valid partition of the node samples is found, even if it requires to<br>effectively inspect more than ``max_features`` features.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;sqrt&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_leaf_nodes',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=max_leaf_nodes,-int%2C%20default%3DNone\">\n",
       "            max_leaf_nodes\n",
       "            <span class=\"param-doc-description\">max_leaf_nodes: int, default=None<br><br>Grow trees with ``max_leaf_nodes`` in best-first fashion.<br>Best nodes are defined as relative reduction in impurity.<br>If None then unlimited number of leaf nodes.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_impurity_decrease',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=min_impurity_decrease,-float%2C%20default%3D0.0\">\n",
       "            min_impurity_decrease\n",
       "            <span class=\"param-doc-description\">min_impurity_decrease: float, default=0.0<br><br>A node will be split if this split induces a decrease of the impurity<br>greater than or equal to this value.<br><br>The weighted impurity decrease equation is the following::<br><br>    N_t / N * (impurity - N_t_R / N_t * right_impurity<br>                        - N_t_L / N_t * left_impurity)<br><br>where ``N`` is the total number of samples, ``N_t`` is the number of<br>samples at the current node, ``N_t_L`` is the number of samples in the<br>left child, and ``N_t_R`` is the number of samples in the right child.<br><br>``N``, ``N_t``, ``N_t_R`` and ``N_t_L`` all refer to the weighted sum,<br>if ``sample_weight`` is passed.<br><br>.. versionadded:: 0.19</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('bootstrap',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=bootstrap,-bool%2C%20default%3DTrue\">\n",
       "            bootstrap\n",
       "            <span class=\"param-doc-description\">bootstrap: bool, default=True<br><br>Whether bootstrap samples are used when building trees. If False, the<br>whole dataset is used to build each tree.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('oob_score',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=oob_score,-bool%20or%20callable%2C%20default%3DFalse\">\n",
       "            oob_score\n",
       "            <span class=\"param-doc-description\">oob_score: bool or callable, default=False<br><br>Whether to use out-of-bag samples to estimate the generalization score.<br>By default, :func:`~sklearn.metrics.accuracy_score` is used.<br>Provide a callable with signature `metric(y_true, y_pred)` to use a<br>custom metric. Only available if `bootstrap=True`.<br><br>For an illustration of out-of-bag (OOB) error estimation, see the example<br>:ref:`sphx_glr_auto_examples_ensemble_plot_ensemble_oob.py`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=n_jobs,-int%2C%20default%3DNone\">\n",
       "            n_jobs\n",
       "            <span class=\"param-doc-description\">n_jobs: int, default=None<br><br>The number of jobs to run in parallel. :meth:`fit`, :meth:`predict`,<br>:meth:`decision_path` and :meth:`apply` are all parallelized over the<br>trees. ``None`` means 1 unless in a :obj:`joblib.parallel_backend`<br>context. ``-1`` means using all processors. See :term:`Glossary<br><n_jobs>` for more details.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=random_state,-int%2C%20RandomState%20instance%20or%20None%2C%20default%3DNone\">\n",
       "            random_state\n",
       "            <span class=\"param-doc-description\">random_state: int, RandomState instance or None, default=None<br><br>Controls both the randomness of the bootstrapping of the samples used<br>when building trees (if ``bootstrap=True``) and the sampling of the<br>features to consider when looking for the best split at each node<br>(if ``max_features < n_features``).<br>See :term:`Glossary <random_state>` for details.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">42</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=verbose,-int%2C%20default%3D0\">\n",
       "            verbose\n",
       "            <span class=\"param-doc-description\">verbose: int, default=0<br><br>Controls the verbosity when fitting and predicting.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('warm_start',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=warm_start,-bool%2C%20default%3DFalse\">\n",
       "            warm_start\n",
       "            <span class=\"param-doc-description\">warm_start: bool, default=False<br><br>When set to ``True``, reuse the solution of the previous call to fit<br>and add more estimators to the ensemble, otherwise, just fit a whole<br>new forest. See :term:`Glossary <warm_start>` and<br>:ref:`tree_ensemble_warm_start` for details.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('class_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=class_weight,-%7B%22balanced%22%2C%20%22balanced_subsample%22%7D%2C%20dict%20or%20list%20of%20dicts%2C%20%20%20%20%20%20%20%20%20%20%20%20%20default%3DNone\">\n",
       "            class_weight\n",
       "            <span class=\"param-doc-description\">class_weight: {\"balanced\", \"balanced_subsample\"}, dict or list of dicts,             default=None<br><br>Weights associated with classes in the form ``{class_label: weight}``.<br>If not given, all classes are supposed to have weight one. For<br>multi-output problems, a list of dicts can be provided in the same<br>order as the columns of y.<br><br>Note that for multioutput (including multilabel) weights should be<br>defined for each class of every column in its own dict. For example,<br>for four-class multilabel classification weights should be<br>[{0: 1, 1: 1}, {0: 1, 1: 5}, {0: 1, 1: 1}, {0: 1, 1: 1}] instead of<br>[{1:1}, {2:5}, {3:1}, {4:1}].<br><br>The \"balanced\" mode uses the values of y to automatically adjust<br>weights inversely proportional to class frequencies in the input data<br>as ``n_samples / (n_classes * np.bincount(y))``<br><br>The \"balanced_subsample\" mode is the same as \"balanced\" except that<br>weights are computed based on the bootstrap sample for every tree<br>grown.<br><br>For multi-output, the weights of each column of y will be multiplied.<br><br>Note that these weights will be multiplied with sample_weight (passed<br>through the fit method) if sample_weight is specified.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('ccp_alpha',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=ccp_alpha,-non-negative%20float%2C%20default%3D0.0\">\n",
       "            ccp_alpha\n",
       "            <span class=\"param-doc-description\">ccp_alpha: non-negative float, default=0.0<br><br>Complexity parameter used for Minimal Cost-Complexity Pruning. The<br>subtree with the largest cost complexity that is smaller than<br>``ccp_alpha`` will be chosen. By default, no pruning is performed. See<br>:ref:`minimal_cost_complexity_pruning` for details. See<br>:ref:`sphx_glr_auto_examples_tree_plot_cost_complexity_pruning.py`<br>for an example of such pruning.<br><br>.. versionadded:: 0.22</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_samples',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=max_samples,-int%20or%20float%2C%20default%3DNone\">\n",
       "            max_samples\n",
       "            <span class=\"param-doc-description\">max_samples: int or float, default=None<br><br>If bootstrap is True, the number of samples to draw from X<br>to train each base estimator.<br><br>- If None (default), then draw `X.shape[0]` samples.<br>- If int, then draw `max_samples` samples.<br>- If float, then draw `max(round(n_samples * max_samples), 1)` samples. Thus,<br>  `max_samples` should be in the interval `(0.0, 1.0]`.<br><br>.. versionadded:: 0.22</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('monotonic_cst',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=monotonic_cst,-array-like%20of%20int%20of%20shape%20%28n_features%29%2C%20default%3DNone\">\n",
       "            monotonic_cst\n",
       "            <span class=\"param-doc-description\">monotonic_cst: array-like of int of shape (n_features), default=None<br><br>Indicates the monotonicity constraint to enforce on each feature.<br>  - 1: monotonic increase<br>  - 0: no constraint<br>  - -1: monotonic decrease<br><br>If monotonic_cst is None, no constraints are applied.<br><br>Monotonicity constraints are not supported for:<br>  - multiclass classifications (i.e. when `n_classes > 2`),<br>  - multioutput classifications (i.e. when `n_outputs_ > 1`),<br>  - classifications trained on data with missing values.<br><br>The constraints hold over the probability of the positive class.<br><br>Read more in the :ref:`User Guide <monotonic_cst_gbdt>`.<br><br>.. versionadded:: 1.4</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.copy-paste-icon').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling\n",
       "        .textContent.trim().split(' ')[0];\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "\n",
       "\n",
       "/**\n",
       " * Adapted from Skrub\n",
       " * https://github.com/skrub-data/skrub/blob/403466d1d5d4dc76a7ef569b3f8228db59a31dc3/skrub/_reporting/_data/templates/report.js#L789\n",
       " * @returns \"light\" or \"dark\"\n",
       " */\n",
       "function detectTheme(element) {\n",
       "    const body = document.querySelector('body');\n",
       "\n",
       "    // Check VSCode theme\n",
       "    const themeKindAttr = body.getAttribute('data-vscode-theme-kind');\n",
       "    const themeNameAttr = body.getAttribute('data-vscode-theme-name');\n",
       "\n",
       "    if (themeKindAttr && themeNameAttr) {\n",
       "        const themeKind = themeKindAttr.toLowerCase();\n",
       "        const themeName = themeNameAttr.toLowerCase();\n",
       "\n",
       "        if (themeKind.includes(\"dark\") || themeName.includes(\"dark\")) {\n",
       "            return \"dark\";\n",
       "        }\n",
       "        if (themeKind.includes(\"light\") || themeName.includes(\"light\")) {\n",
       "            return \"light\";\n",
       "        }\n",
       "    }\n",
       "\n",
       "    // Check Jupyter theme\n",
       "    if (body.getAttribute('data-jp-theme-light') === 'false') {\n",
       "        return 'dark';\n",
       "    } else if (body.getAttribute('data-jp-theme-light') === 'true') {\n",
       "        return 'light';\n",
       "    }\n",
       "\n",
       "    // Guess based on a parent element's color\n",
       "    const color = window.getComputedStyle(element.parentNode, null).getPropertyValue('color');\n",
       "    const match = color.match(/^rgb\\s*\\(\\s*(\\d+)\\s*,\\s*(\\d+)\\s*,\\s*(\\d+)\\s*\\)\\s*$/i);\n",
       "    if (match) {\n",
       "        const [r, g, b] = [\n",
       "            parseFloat(match[1]),\n",
       "            parseFloat(match[2]),\n",
       "            parseFloat(match[3])\n",
       "        ];\n",
       "\n",
       "        // https://en.wikipedia.org/wiki/HSL_and_HSV#Lightness\n",
       "        const luma = 0.299 * r + 0.587 * g + 0.114 * b;\n",
       "\n",
       "        if (luma > 180) {\n",
       "            // If the text is very bright we have a dark theme\n",
       "            return 'dark';\n",
       "        }\n",
       "        if (luma < 75) {\n",
       "            // If the text is very dark we have a light theme\n",
       "            return 'light';\n",
       "        }\n",
       "        // Otherwise fall back to the next heuristic.\n",
       "    }\n",
       "\n",
       "    // Fallback to system preference\n",
       "    return window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light';\n",
       "}\n",
       "\n",
       "\n",
       "function forceTheme(elementId) {\n",
       "    const estimatorElement = document.querySelector(`#${elementId}`);\n",
       "    if (estimatorElement === null) {\n",
       "        console.error(`Element with id ${elementId} not found.`);\n",
       "    } else {\n",
       "        const theme = detectTheme(estimatorElement);\n",
       "        estimatorElement.classList.add(theme);\n",
       "    }\n",
       "}\n",
       "\n",
       "forceTheme('sk-container-id-4');</script></body>"
      ],
      "text/plain": [
       "RandomForestClassifier(random_state=42)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train RandomForest classifier\n",
    "rf_model = RandomForestClassifier(\n",
    "    random_state=42,\n",
    "    n_estimators=100,\n",
    ")\n",
    "\n",
    "print('Training RandomForest...')\n",
    "rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Accuracy: 0.7880 (78.80%)\n"
     ]
    }
   ],
   "source": [
    "# Evaluate RandomForest on validation set\n",
    "y_pred_rf = rf_model.predict(X_val)\n",
    "accuracy_rf = (y_pred_rf == y_val).mean()\n",
    "\n",
    "print(f'\\nValidation Accuracy: {accuracy_rf:.4f} ({accuracy_rf*100:.2f}%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Improve Mobilenet V1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diff head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: conv_pad_12\n",
      "  Type: ZeroPadding2D\n",
      "  Output Shape: (None, 15, 15, 512)\n",
      "  Params: 0\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: conv_dw_12\n",
      "  Type: DepthwiseConv2D\n",
      "  Output Shape: (None, 7, 7, 512)\n",
      "  Params: 4608\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: conv_dw_12_bn\n",
      "  Type: BatchNormalization\n",
      "  Output Shape: (None, 7, 7, 512)\n",
      "  Params: 2048\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: conv_dw_12_relu\n",
      "  Type: ReLU\n",
      "  Output Shape: (None, 7, 7, 512)\n",
      "  Params: 0\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: conv_pw_12\n",
      "  Type: Conv2D\n",
      "  Output Shape: (None, 7, 7, 1024)\n",
      "  Params: 524288\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: conv_pw_12_bn\n",
      "  Type: BatchNormalization\n",
      "  Output Shape: (None, 7, 7, 1024)\n",
      "  Params: 4096\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: conv_pw_12_relu\n",
      "  Type: ReLU\n",
      "  Output Shape: (None, 7, 7, 1024)\n",
      "  Params: 0\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: conv_dw_13\n",
      "  Type: DepthwiseConv2D\n",
      "  Output Shape: (None, 7, 7, 1024)\n",
      "  Params: 9216\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: conv_dw_13_bn\n",
      "  Type: BatchNormalization\n",
      "  Output Shape: (None, 7, 7, 1024)\n",
      "  Params: 4096\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: conv_dw_13_relu\n",
      "  Type: ReLU\n",
      "  Output Shape: (None, 7, 7, 1024)\n",
      "  Params: 0\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: conv_pw_13\n",
      "  Type: Conv2D\n",
      "  Output Shape: (None, 7, 7, 1024)\n",
      "  Params: 1048576\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: conv_pw_13_bn\n",
      "  Type: BatchNormalization\n",
      "  Output Shape: (None, 7, 7, 1024)\n",
      "  Params: 4096\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: conv_pw_13_relu\n",
      "  Type: ReLU\n",
      "  Output Shape: (None, 7, 7, 1024)\n",
      "  Params: 0\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: global_average_pooling2d_11\n",
      "  Type: GlobalAveragePooling2D\n",
      "  Output Shape: (None, 1024)\n",
      "  Params: 0\n",
      " Trainable: True\n",
      "--------------------------------------------------\n",
      "Layer: dense_9\n",
      "  Type: Dense\n",
      "  Output Shape: (None, 512)\n",
      "  Params: 524800\n",
      " Trainable: True\n",
      "--------------------------------------------------\n",
      "Layer: batch_normalization_2\n",
      "  Type: BatchNormalization\n",
      "  Output Shape: (None, 512)\n",
      "  Params: 2048\n",
      " Trainable: True\n",
      "--------------------------------------------------\n",
      "Layer: dropout_4\n",
      "  Type: Dropout\n",
      "  Output Shape: (None, 512)\n",
      "  Params: 0\n",
      " Trainable: True\n",
      "--------------------------------------------------\n",
      "Layer: dense_10\n",
      "  Type: Dense\n",
      "  Output Shape: (None, 256)\n",
      "  Params: 131328\n",
      " Trainable: True\n",
      "--------------------------------------------------\n",
      "Layer: dropout_5\n",
      "  Type: Dropout\n",
      "  Output Shape: (None, 256)\n",
      "  Params: 0\n",
      " Trainable: True\n",
      "--------------------------------------------------\n",
      "Layer: dense_11\n",
      "  Type: Dense\n",
      "  Output Shape: (None, 10)\n",
      "  Params: 2570\n",
      " Trainable: True\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "base_model = MobileNet(\n",
    "    include_top=True, \n",
    "    weights='imagenet'\n",
    ")\n",
    "\n",
    "base_model.trainable = False\n",
    "\n",
    "x = base_model.get_layer(\"conv_pw_13_relu\").output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "output = Dense(10, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "for layer in model.layers[-20:]:\n",
    "    print(f\"Layer: {layer.name}\")\n",
    "    print(f\"  Type: {layer.__class__.__name__}\")\n",
    "    print(f\"  Output Shape: {layer.output.shape}\")\n",
    "    print(f\"  Params: {layer.count_params()}\")\n",
    "    print(f\" Trainable: {layer.trainable}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "45/45 [==============================] - 13s 255ms/step - loss: 1.0736 - accuracy: 0.6494 - val_loss: 0.8472 - val_accuracy: 0.6934 - lr: 0.0010\n",
      "Epoch 2/30\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.3723 - accuracy: 0.8722 - val_loss: 0.6953 - val_accuracy: 0.7679 - lr: 0.0010\n",
      "Epoch 3/30\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.3239 - accuracy: 0.8935 - val_loss: 0.4924 - val_accuracy: 0.8453 - lr: 0.0010\n",
      "Epoch 4/30\n",
      "45/45 [==============================] - 11s 245ms/step - loss: 0.2315 - accuracy: 0.9304 - val_loss: 0.5398 - val_accuracy: 0.8195 - lr: 0.0010\n",
      "Epoch 5/30\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.2113 - accuracy: 0.9191 - val_loss: 0.4886 - val_accuracy: 0.8424 - lr: 0.0010\n",
      "Epoch 6/30\n",
      "45/45 [==============================] - 12s 256ms/step - loss: 0.1841 - accuracy: 0.9411 - val_loss: 0.6020 - val_accuracy: 0.8338 - lr: 0.0010\n",
      "Epoch 7/30\n",
      "45/45 [==============================] - 12s 258ms/step - loss: 0.1719 - accuracy: 0.9390 - val_loss: 0.4412 - val_accuracy: 0.8854 - lr: 0.0010\n",
      "Epoch 8/30\n",
      "45/45 [==============================] - 11s 249ms/step - loss: 0.1761 - accuracy: 0.9354 - val_loss: 0.4926 - val_accuracy: 0.8596 - lr: 0.0010\n",
      "Epoch 9/30\n",
      "45/45 [==============================] - 11s 249ms/step - loss: 0.1329 - accuracy: 0.9574 - val_loss: 0.5048 - val_accuracy: 0.8510 - lr: 0.0010\n",
      "Epoch 10/30\n",
      "45/45 [==============================] - 11s 247ms/step - loss: 0.1251 - accuracy: 0.9567 - val_loss: 0.4684 - val_accuracy: 0.8625 - lr: 0.0010\n",
      "Epoch 11/30\n",
      "45/45 [==============================] - 11s 252ms/step - loss: 0.1046 - accuracy: 0.9702 - val_loss: 0.4005 - val_accuracy: 0.8682 - lr: 5.0000e-04\n",
      "Epoch 12/30\n",
      "45/45 [==============================] - 11s 249ms/step - loss: 0.1123 - accuracy: 0.9588 - val_loss: 0.3794 - val_accuracy: 0.8797 - lr: 5.0000e-04\n",
      "Epoch 13/30\n",
      "45/45 [==============================] - 11s 254ms/step - loss: 0.0887 - accuracy: 0.9716 - val_loss: 0.3582 - val_accuracy: 0.8797 - lr: 5.0000e-04\n",
      "Epoch 14/30\n",
      "45/45 [==============================] - 11s 249ms/step - loss: 0.0935 - accuracy: 0.9688 - val_loss: 0.3328 - val_accuracy: 0.8854 - lr: 5.0000e-04\n",
      "Epoch 15/30\n",
      "45/45 [==============================] - 11s 249ms/step - loss: 0.0804 - accuracy: 0.9695 - val_loss: 0.3432 - val_accuracy: 0.8825 - lr: 5.0000e-04\n",
      "Epoch 16/30\n",
      "45/45 [==============================] - 11s 248ms/step - loss: 0.0823 - accuracy: 0.9744 - val_loss: 0.5233 - val_accuracy: 0.8539 - lr: 5.0000e-04\n",
      "Epoch 17/30\n",
      "45/45 [==============================] - 11s 249ms/step - loss: 0.0873 - accuracy: 0.9638 - val_loss: 0.5470 - val_accuracy: 0.8539 - lr: 5.0000e-04\n",
      "Epoch 18/30\n",
      "45/45 [==============================] - 11s 248ms/step - loss: 0.0801 - accuracy: 0.9766 - val_loss: 0.4316 - val_accuracy: 0.8625 - lr: 2.5000e-04\n",
      "Epoch 19/30\n",
      "45/45 [==============================] - 12s 256ms/step - loss: 0.0852 - accuracy: 0.9674 - val_loss: 0.4126 - val_accuracy: 0.8739 - lr: 2.5000e-04\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=validation_generator,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=callbacks + [ModelCheckpoint('mobilenet_head.h5', save_best_only=True)],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = Path('./mobilenet_head.h5')\n",
    "model = keras.models.load_model(model_path)\n",
    "\n",
    "model.trainable = True\n",
    "\n",
    "for layer in model.layers[:-35]:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(5e-5),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "45/45 [==============================] - 13s 255ms/step - loss: 0.3083 - accuracy: 0.8943 - val_loss: 0.4820 - val_accuracy: 0.8481 - lr: 5.0000e-05\n",
      "Epoch 2/30\n",
      "45/45 [==============================] - 11s 249ms/step - loss: 0.1602 - accuracy: 0.9482 - val_loss: 0.4044 - val_accuracy: 0.8653 - lr: 5.0000e-05\n",
      "Epoch 3/30\n",
      "45/45 [==============================] - 11s 254ms/step - loss: 0.1258 - accuracy: 0.9532 - val_loss: 0.3246 - val_accuracy: 0.8940 - lr: 5.0000e-05\n",
      "Epoch 4/30\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.0840 - accuracy: 0.9759 - val_loss: 0.3083 - val_accuracy: 0.8911 - lr: 5.0000e-05\n",
      "Epoch 5/30\n",
      "45/45 [==============================] - 11s 254ms/step - loss: 0.0821 - accuracy: 0.9716 - val_loss: 0.2711 - val_accuracy: 0.9112 - lr: 5.0000e-05\n",
      "Epoch 6/30\n",
      "45/45 [==============================] - 11s 248ms/step - loss: 0.0568 - accuracy: 0.9830 - val_loss: 0.2965 - val_accuracy: 0.8911 - lr: 5.0000e-05\n",
      "Epoch 7/30\n",
      "45/45 [==============================] - 12s 255ms/step - loss: 0.0519 - accuracy: 0.9808 - val_loss: 0.2691 - val_accuracy: 0.8940 - lr: 5.0000e-05\n",
      "Epoch 8/30\n",
      "45/45 [==============================] - 11s 246ms/step - loss: 0.0481 - accuracy: 0.9844 - val_loss: 0.3373 - val_accuracy: 0.8911 - lr: 5.0000e-05\n",
      "Epoch 9/30\n",
      "45/45 [==============================] - 11s 252ms/step - loss: 0.0393 - accuracy: 0.9844 - val_loss: 0.3126 - val_accuracy: 0.8854 - lr: 5.0000e-05\n",
      "Epoch 10/30\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.0397 - accuracy: 0.9851 - val_loss: 0.3454 - val_accuracy: 0.8797 - lr: 5.0000e-05\n",
      "Epoch 11/30\n",
      "45/45 [==============================] - 12s 258ms/step - loss: 0.0411 - accuracy: 0.9858 - val_loss: 0.2857 - val_accuracy: 0.8940 - lr: 2.5000e-05\n",
      "Epoch 12/30\n",
      "45/45 [==============================] - 12s 258ms/step - loss: 0.0301 - accuracy: 0.9894 - val_loss: 0.2438 - val_accuracy: 0.9083 - lr: 2.5000e-05\n",
      "Epoch 13/30\n",
      "45/45 [==============================] - 12s 258ms/step - loss: 0.0287 - accuracy: 0.9894 - val_loss: 0.2660 - val_accuracy: 0.9083 - lr: 2.5000e-05\n",
      "Epoch 14/30\n",
      "45/45 [==============================] - 11s 252ms/step - loss: 0.0241 - accuracy: 0.9922 - val_loss: 0.2796 - val_accuracy: 0.8997 - lr: 2.5000e-05\n",
      "Epoch 15/30\n",
      "45/45 [==============================] - 12s 261ms/step - loss: 0.0323 - accuracy: 0.9879 - val_loss: 0.2202 - val_accuracy: 0.9198 - lr: 2.5000e-05\n",
      "Epoch 16/30\n",
      "45/45 [==============================] - 11s 252ms/step - loss: 0.0258 - accuracy: 0.9915 - val_loss: 0.2023 - val_accuracy: 0.9226 - lr: 2.5000e-05\n",
      "Epoch 17/30\n",
      "45/45 [==============================] - 11s 258ms/step - loss: 0.0213 - accuracy: 0.9936 - val_loss: 0.2117 - val_accuracy: 0.9226 - lr: 2.5000e-05\n",
      "Epoch 18/30\n",
      "45/45 [==============================] - 11s 246ms/step - loss: 0.0278 - accuracy: 0.9886 - val_loss: 0.2167 - val_accuracy: 0.9140 - lr: 2.5000e-05\n",
      "Epoch 19/30\n",
      "45/45 [==============================] - 11s 252ms/step - loss: 0.0256 - accuracy: 0.9929 - val_loss: 0.2031 - val_accuracy: 0.9284 - lr: 2.5000e-05\n",
      "Epoch 20/30\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.0160 - accuracy: 0.9965 - val_loss: 0.1983 - val_accuracy: 0.9341 - lr: 1.2500e-05\n",
      "Epoch 21/30\n",
      "45/45 [==============================] - 12s 258ms/step - loss: 0.0236 - accuracy: 0.9901 - val_loss: 0.2264 - val_accuracy: 0.9169 - lr: 1.2500e-05\n",
      "Epoch 22/30\n",
      "45/45 [==============================] - 11s 247ms/step - loss: 0.0242 - accuracy: 0.9908 - val_loss: 0.2209 - val_accuracy: 0.9198 - lr: 1.2500e-05\n",
      "Epoch 23/30\n",
      "45/45 [==============================] - 11s 252ms/step - loss: 0.0177 - accuracy: 0.9943 - val_loss: 0.2192 - val_accuracy: 0.9226 - lr: 1.2500e-05\n",
      "Epoch 24/30\n",
      "45/45 [==============================] - 11s 253ms/step - loss: 0.0298 - accuracy: 0.9894 - val_loss: 0.2160 - val_accuracy: 0.9226 - lr: 6.2500e-06\n",
      "Epoch 25/30\n",
      "45/45 [==============================] - 12s 258ms/step - loss: 0.0166 - accuracy: 0.9950 - val_loss: 0.2184 - val_accuracy: 0.9198 - lr: 6.2500e-06\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=validation_generator,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=callbacks + [ModelCheckpoint('mobilenet_head_unfreezed.h5', save_best_only=True)],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-train w/ unfreezed layers and lower lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = Path('./mobilenet.h5')\n",
    "model = keras.models.load_model(model_path)\n",
    "\n",
    "model.trainable = True\n",
    "\n",
    "for layer in model.layers[:-30]:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(5e-5),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "45/45 [==============================] - 13s 252ms/step - loss: 0.4141 - accuracy: 0.8715 - val_loss: 0.8328 - val_accuracy: 0.7794 - lr: 5.0000e-05\n",
      "Epoch 2/30\n",
      "45/45 [==============================] - 11s 244ms/step - loss: 0.1029 - accuracy: 0.9702 - val_loss: 0.8816 - val_accuracy: 0.7622 - lr: 5.0000e-05\n",
      "Epoch 3/30\n",
      "45/45 [==============================] - 12s 259ms/step - loss: 0.0866 - accuracy: 0.9766 - val_loss: 0.7522 - val_accuracy: 0.7765 - lr: 5.0000e-05\n",
      "Epoch 4/30\n",
      "45/45 [==============================] - 11s 246ms/step - loss: 0.0614 - accuracy: 0.9858 - val_loss: 0.7675 - val_accuracy: 0.7794 - lr: 5.0000e-05\n",
      "Epoch 5/30\n",
      "45/45 [==============================] - 12s 256ms/step - loss: 0.0599 - accuracy: 0.9858 - val_loss: 0.6757 - val_accuracy: 0.7908 - lr: 5.0000e-05\n",
      "Epoch 6/30\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.0470 - accuracy: 0.9929 - val_loss: 0.6413 - val_accuracy: 0.8023 - lr: 5.0000e-05\n",
      "Epoch 7/30\n",
      "45/45 [==============================] - 12s 257ms/step - loss: 0.0405 - accuracy: 0.9922 - val_loss: 0.5769 - val_accuracy: 0.8309 - lr: 5.0000e-05\n",
      "Epoch 8/30\n",
      "45/45 [==============================] - 11s 253ms/step - loss: 0.0343 - accuracy: 0.9936 - val_loss: 0.4038 - val_accuracy: 0.8625 - lr: 5.0000e-05\n",
      "Epoch 9/30\n",
      "45/45 [==============================] - 11s 253ms/step - loss: 0.0338 - accuracy: 0.9929 - val_loss: 0.4387 - val_accuracy: 0.8510 - lr: 5.0000e-05\n",
      "Epoch 10/30\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.0283 - accuracy: 0.9915 - val_loss: 0.3933 - val_accuracy: 0.8653 - lr: 5.0000e-05\n",
      "Epoch 11/30\n",
      "45/45 [==============================] - 12s 259ms/step - loss: 0.0227 - accuracy: 0.9943 - val_loss: 0.3499 - val_accuracy: 0.8768 - lr: 5.0000e-05\n",
      "Epoch 12/30\n",
      "45/45 [==============================] - 11s 253ms/step - loss: 0.0246 - accuracy: 0.9922 - val_loss: 0.2878 - val_accuracy: 0.9054 - lr: 5.0000e-05\n",
      "Epoch 13/30\n",
      "45/45 [==============================] - 12s 255ms/step - loss: 0.0260 - accuracy: 0.9936 - val_loss: 0.2677 - val_accuracy: 0.9112 - lr: 5.0000e-05\n",
      "Epoch 14/30\n",
      "45/45 [==============================] - 11s 248ms/step - loss: 0.0190 - accuracy: 0.9965 - val_loss: 0.3640 - val_accuracy: 0.8854 - lr: 5.0000e-05\n",
      "Epoch 15/30\n",
      "45/45 [==============================] - 12s 258ms/step - loss: 0.0280 - accuracy: 0.9922 - val_loss: 0.2499 - val_accuracy: 0.9169 - lr: 5.0000e-05\n",
      "Epoch 16/30\n",
      "45/45 [==============================] - 11s 253ms/step - loss: 0.0170 - accuracy: 0.9972 - val_loss: 0.2801 - val_accuracy: 0.9054 - lr: 5.0000e-05\n",
      "Epoch 17/30\n",
      "45/45 [==============================] - 11s 254ms/step - loss: 0.0184 - accuracy: 0.9965 - val_loss: 0.2583 - val_accuracy: 0.9284 - lr: 5.0000e-05\n",
      "Epoch 18/30\n",
      "45/45 [==============================] - 11s 246ms/step - loss: 0.0158 - accuracy: 0.9972 - val_loss: 0.2923 - val_accuracy: 0.9169 - lr: 5.0000e-05\n",
      "Epoch 19/30\n",
      "45/45 [==============================] - 12s 255ms/step - loss: 0.0170 - accuracy: 0.9957 - val_loss: 0.2397 - val_accuracy: 0.9226 - lr: 2.5000e-05\n",
      "Epoch 20/30\n",
      "45/45 [==============================] - 11s 253ms/step - loss: 0.0209 - accuracy: 0.9950 - val_loss: 0.2325 - val_accuracy: 0.9198 - lr: 2.5000e-05\n",
      "Epoch 21/30\n",
      "45/45 [==============================] - 12s 257ms/step - loss: 0.0105 - accuracy: 0.9986 - val_loss: 0.2319 - val_accuracy: 0.9169 - lr: 2.5000e-05\n",
      "Epoch 22/30\n",
      "45/45 [==============================] - 11s 252ms/step - loss: 0.0174 - accuracy: 0.9950 - val_loss: 0.2519 - val_accuracy: 0.9083 - lr: 2.5000e-05\n",
      "Epoch 23/30\n",
      "45/45 [==============================] - 12s 255ms/step - loss: 0.0116 - accuracy: 0.9979 - val_loss: 0.2485 - val_accuracy: 0.9169 - lr: 2.5000e-05\n",
      "Epoch 24/30\n",
      "45/45 [==============================] - 11s 245ms/step - loss: 0.0090 - accuracy: 0.9979 - val_loss: 0.2329 - val_accuracy: 0.9255 - lr: 2.5000e-05\n",
      "Epoch 25/30\n",
      "45/45 [==============================] - 12s 258ms/step - loss: 0.0101 - accuracy: 0.9972 - val_loss: 0.2239 - val_accuracy: 0.9255 - lr: 1.2500e-05\n",
      "Epoch 26/30\n",
      "45/45 [==============================] - 11s 254ms/step - loss: 0.0110 - accuracy: 0.9993 - val_loss: 0.2205 - val_accuracy: 0.9284 - lr: 1.2500e-05\n",
      "Epoch 27/30\n",
      "45/45 [==============================] - 12s 257ms/step - loss: 0.0103 - accuracy: 0.9979 - val_loss: 0.2021 - val_accuracy: 0.9312 - lr: 1.2500e-05\n",
      "Epoch 28/30\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.0104 - accuracy: 0.9979 - val_loss: 0.1963 - val_accuracy: 0.9341 - lr: 1.2500e-05\n",
      "Epoch 29/30\n",
      "45/45 [==============================] - 11s 252ms/step - loss: 0.0108 - accuracy: 0.9972 - val_loss: 0.1977 - val_accuracy: 0.9427 - lr: 1.2500e-05\n",
      "Epoch 30/30\n",
      "45/45 [==============================] - 11s 246ms/step - loss: 0.0088 - accuracy: 0.9993 - val_loss: 0.2000 - val_accuracy: 0.9370 - lr: 1.2500e-05\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=validation_generator,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=callbacks + [ModelCheckpoint('mobilenet_unfreezed.h5', save_best_only=True)],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Evaluate Model\n",
    "Testing on unseen eval dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 304 images belonging to 10 classes.\n",
      "Evaluating model on eval dataset...\n",
      "10/10 [==============================] - 1s 83ms/step - loss: 0.0957 - accuracy: 0.9737\n",
      "\n",
      "Eval Loss: 0.0957\n",
      "Eval Accuracy: 0.9737\n"
     ]
    }
   ],
   "source": [
    "model_path = Path('./mobilenet_unfreezed.h5')\n",
    "model = keras.models.load_model(model_path)\n",
    "eval_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "eval_generator = eval_datagen.flow_from_directory(\n",
    "    TEST_PATH,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "print('Evaluating model on eval dataset...')\n",
    "eval_loss, eval_accuracy = model.evaluate(eval_generator)\n",
    "print(f'\\nEval Loss: {eval_loss:.4f}')\n",
    "print(f'Eval Accuracy: {eval_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Confusion Matrix & Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 1s 84ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98        30\n",
      "           1       1.00      1.00      1.00        30\n",
      "           2       0.97      0.97      0.97        30\n",
      "           3       1.00      0.90      0.95        30\n",
      "           4       1.00      1.00      1.00        31\n",
      "           5       1.00      1.00      1.00        31\n",
      "           6       1.00      1.00      1.00        31\n",
      "           7       0.88      0.97      0.92        30\n",
      "           8       0.93      0.90      0.92        31\n",
      "           9       1.00      1.00      1.00        30\n",
      "\n",
      "    accuracy                           0.97       304\n",
      "   macro avg       0.97      0.97      0.97       304\n",
      "weighted avg       0.97      0.97      0.97       304\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate predictions for confusion matrix\n",
    "eval_generator.reset()\n",
    "predictions = model.predict(eval_generator, verbose=1)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "true_classes = eval_generator.classes\n",
    "\n",
    "# Create confusion matrix\n",
    "cm = confusion_matrix(true_classes, predicted_classes)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=range(10), yticklabels=range(10))\n",
    "plt.title('Confusion Matrix - Sign Language Digits')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.show()\n",
    "\n",
    "# Print classification report\n",
    "print('\\nClassification Report:')\n",
    "print(classification_report(true_classes, predicted_classes, \n",
    "                          target_names=[str(i) for i in range(10)]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
