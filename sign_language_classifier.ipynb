{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sign Language Digits Classifier\n",
    "Using MobileNet transfer learning to classify ASL digits (0-9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.applications import MobileNetV2, MobileNet, MobileNetV3Small\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras.applications.mobilenet import preprocess_input\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.20.0\n",
      "Built with CUDA: True\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"Built with CUDA:\", tf.test.is_built_with_cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(\"Num GPUs Available: \", len(physical_devices))\n",
    "if physical_devices:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Set Project Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project constants\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 30\n",
    "VALIDATION_SPLIT = 0.2\n",
    "NUM_CLASSES = 10\n",
    "\n",
    "# Paths\n",
    "DATASET_PATH = 'Sign-Language-Digits-Dataset/Dataset'\n",
    "TRAIN_PATH = 'Sign-Language-Digits-Dataset/training'\n",
    "TEST_PATH = 'Sign-Language-Digits-Dataset/test'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create Dataset Splits\n",
    "Creating training/ folder (85% of dataset) and test/ folder (15% of dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating training/test split...\n",
      "Digit 0: 175 training, 30 test\n",
      "Digit 1: 176 training, 30 test\n",
      "Digit 2: 176 training, 30 test\n",
      "Digit 3: 176 training, 30 test\n",
      "Digit 4: 176 training, 31 test\n",
      "Digit 5: 176 training, 31 test\n",
      "Digit 6: 176 training, 31 test\n",
      "Digit 7: 176 training, 30 test\n",
      "Digit 8: 177 training, 31 test\n",
      "Digit 9: 174 training, 30 test\n",
      "\n",
      "Total training images: 1758 (85.3%)\n",
      "Total test images: 304 (14.7%)\n"
     ]
    }
   ],
   "source": [
    "# Create training/ and test/ folders with 85/15 split\n",
    "def create_train_test_split(source_path, train_path, test_path, test_split=0.15):\n",
    "    \"\"\"Split dataset into training (85%) and test (15%) folders\"\"\"\n",
    "    \n",
    "    # Remove destination folders if they exist\n",
    "    for path in [train_path, test_path]:\n",
    "        if os.path.exists(path):\n",
    "            shutil.rmtree(path)\n",
    "        os.makedirs(path)\n",
    "    \n",
    "    total_train_images = 0\n",
    "    total_test_images = 0\n",
    "    \n",
    "    # Process each digit (0-9)\n",
    "    for digit in range(10):\n",
    "        digit_source = os.path.join(source_path, str(digit))\n",
    "        digit_train = os.path.join(train_path, str(digit))\n",
    "        digit_test = os.path.join(test_path, str(digit))\n",
    "        \n",
    "        os.makedirs(digit_train)\n",
    "        os.makedirs(digit_test)\n",
    "        \n",
    "        # Get all images for this digit\n",
    "        all_images = [f for f in os.listdir(digit_source) if f.endswith('.JPG')]\n",
    "        \n",
    "        # Shuffle images\n",
    "        random.shuffle(all_images)\n",
    "        \n",
    "        # Calculate split point (15% for test, 85% for training)\n",
    "        num_test = int(len(all_images) * test_split)\n",
    "        num_train = len(all_images) - num_test\n",
    "        \n",
    "        # Split images\n",
    "        test_images = all_images[:num_test]\n",
    "        train_images = all_images[num_test:]\n",
    "        \n",
    "        # Copy test images\n",
    "        for img in test_images:\n",
    "            src = os.path.join(digit_source, img)\n",
    "            dst = os.path.join(digit_test, img)\n",
    "            shutil.copy2(src, dst)\n",
    "        \n",
    "        # Copy training images\n",
    "        for img in train_images:\n",
    "            src = os.path.join(digit_source, img)\n",
    "            dst = os.path.join(digit_train, img)\n",
    "            shutil.copy2(src, dst)\n",
    "        \n",
    "        total_train_images += num_train\n",
    "        total_test_images += num_test\n",
    "        \n",
    "        print(f'Digit {digit}: {num_train} training, {num_test} test')\n",
    "    \n",
    "    return total_train_images, total_test_images\n",
    "\n",
    "print('Creating training/test split...')\n",
    "num_train, num_test = create_train_test_split(DATASET_PATH, TRAIN_PATH, TEST_PATH)\n",
    "\n",
    "print(f'\\nTotal training images: {num_train} ({num_train/(num_train+num_test)*100:.1f}%)')\n",
    "print(f'Total test images: {num_test} ({num_test/(num_train+num_test)*100:.1f}%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create Data Generators\n",
    "Setting up training and validation generators with 80/20 split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1409 images belonging to 10 classes.\n",
      "Found 349 images belonging to 10 classes.\n",
      "\n",
      "Training samples: 1409\n",
      "Validation samples: 349\n"
     ]
    }
   ],
   "source": [
    "# Create image data generators with data augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "    validation_split=VALIDATION_SPLIT,\n",
    "    # Data augmentation parameters\n",
    "    rotation_range=15,              # Randomly rotate images by up to 15 degrees\n",
    "    zoom_range=0.15,                # Randomly zoom in/out by up to 15%\n",
    "    brightness_range=[0.8, 1.2],    # Randomly adjust brightness\n",
    "    fill_mode='nearest'             # Fill pixels after transformations\n",
    ")\n",
    "\n",
    "# Validation generator (no augmentation, only rescaling)\n",
    "val_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "    validation_split=VALIDATION_SPLIT\n",
    ")\n",
    "\n",
    "# Training generator\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    TRAIN_PATH,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    subset='training',\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# Validation generator\n",
    "validation_generator = val_datagen.flow_from_directory(\n",
    "    TRAIN_PATH,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    subset='validation',\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "print(f'\\nTraining samples: {train_generator.samples}')\n",
    "print(f'Validation samples: {validation_generator.samples}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Build Model Architecture\n",
    "Using MobileNetV2 as base model with frozen weights, adding custom classification head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: conv_dw_10\n",
      "  Type: DepthwiseConv2D\n",
      "  Output Shape: (None, 14, 14, 512)\n",
      "  Params: 4608\n",
      "--------------------------------------------------\n",
      "Layer: conv_dw_10_bn\n",
      "  Type: BatchNormalization\n",
      "  Output Shape: (None, 14, 14, 512)\n",
      "  Params: 2048\n",
      "--------------------------------------------------\n",
      "Layer: conv_dw_10_relu\n",
      "  Type: ReLU\n",
      "  Output Shape: (None, 14, 14, 512)\n",
      "  Params: 0\n",
      "--------------------------------------------------\n",
      "Layer: conv_pw_10\n",
      "  Type: Conv2D\n",
      "  Output Shape: (None, 14, 14, 512)\n",
      "  Params: 262144\n",
      "--------------------------------------------------\n",
      "Layer: conv_pw_10_bn\n",
      "  Type: BatchNormalization\n",
      "  Output Shape: (None, 14, 14, 512)\n",
      "  Params: 2048\n",
      "--------------------------------------------------\n",
      "Layer: conv_pw_10_relu\n",
      "  Type: ReLU\n",
      "  Output Shape: (None, 14, 14, 512)\n",
      "  Params: 0\n",
      "--------------------------------------------------\n",
      "Layer: conv_dw_11\n",
      "  Type: DepthwiseConv2D\n",
      "  Output Shape: (None, 14, 14, 512)\n",
      "  Params: 4608\n",
      "--------------------------------------------------\n",
      "Layer: conv_dw_11_bn\n",
      "  Type: BatchNormalization\n",
      "  Output Shape: (None, 14, 14, 512)\n",
      "  Params: 2048\n",
      "--------------------------------------------------\n",
      "Layer: conv_dw_11_relu\n",
      "  Type: ReLU\n",
      "  Output Shape: (None, 14, 14, 512)\n",
      "  Params: 0\n",
      "--------------------------------------------------\n",
      "Layer: conv_pw_11\n",
      "  Type: Conv2D\n",
      "  Output Shape: (None, 14, 14, 512)\n",
      "  Params: 262144\n",
      "--------------------------------------------------\n",
      "Layer: conv_pw_11_bn\n",
      "  Type: BatchNormalization\n",
      "  Output Shape: (None, 14, 14, 512)\n",
      "  Params: 2048\n",
      "--------------------------------------------------\n",
      "Layer: conv_pw_11_relu\n",
      "  Type: ReLU\n",
      "  Output Shape: (None, 14, 14, 512)\n",
      "  Params: 0\n",
      "--------------------------------------------------\n",
      "Layer: conv_pad_12\n",
      "  Type: ZeroPadding2D\n",
      "  Output Shape: (None, 15, 15, 512)\n",
      "  Params: 0\n",
      "--------------------------------------------------\n",
      "Layer: conv_dw_12\n",
      "  Type: DepthwiseConv2D\n",
      "  Output Shape: (None, 7, 7, 512)\n",
      "  Params: 4608\n",
      "--------------------------------------------------\n",
      "Layer: conv_dw_12_bn\n",
      "  Type: BatchNormalization\n",
      "  Output Shape: (None, 7, 7, 512)\n",
      "  Params: 2048\n",
      "--------------------------------------------------\n",
      "Layer: conv_dw_12_relu\n",
      "  Type: ReLU\n",
      "  Output Shape: (None, 7, 7, 512)\n",
      "  Params: 0\n",
      "--------------------------------------------------\n",
      "Layer: conv_pw_12\n",
      "  Type: Conv2D\n",
      "  Output Shape: (None, 7, 7, 1024)\n",
      "  Params: 524288\n",
      "--------------------------------------------------\n",
      "Layer: conv_pw_12_bn\n",
      "  Type: BatchNormalization\n",
      "  Output Shape: (None, 7, 7, 1024)\n",
      "  Params: 4096\n",
      "--------------------------------------------------\n",
      "Layer: conv_pw_12_relu\n",
      "  Type: ReLU\n",
      "  Output Shape: (None, 7, 7, 1024)\n",
      "  Params: 0\n",
      "--------------------------------------------------\n",
      "Layer: conv_dw_13\n",
      "  Type: DepthwiseConv2D\n",
      "  Output Shape: (None, 7, 7, 1024)\n",
      "  Params: 9216\n",
      "--------------------------------------------------\n",
      "Layer: conv_dw_13_bn\n",
      "  Type: BatchNormalization\n",
      "  Output Shape: (None, 7, 7, 1024)\n",
      "  Params: 4096\n",
      "--------------------------------------------------\n",
      "Layer: conv_dw_13_relu\n",
      "  Type: ReLU\n",
      "  Output Shape: (None, 7, 7, 1024)\n",
      "  Params: 0\n",
      "--------------------------------------------------\n",
      "Layer: conv_pw_13\n",
      "  Type: Conv2D\n",
      "  Output Shape: (None, 7, 7, 1024)\n",
      "  Params: 1048576\n",
      "--------------------------------------------------\n",
      "Layer: conv_pw_13_bn\n",
      "  Type: BatchNormalization\n",
      "  Output Shape: (None, 7, 7, 1024)\n",
      "  Params: 4096\n",
      "--------------------------------------------------\n",
      "Layer: conv_pw_13_relu\n",
      "  Type: ReLU\n",
      "  Output Shape: (None, 7, 7, 1024)\n",
      "  Params: 0\n",
      "--------------------------------------------------\n",
      "Layer: global_average_pooling2d_2\n",
      "  Type: GlobalAveragePooling2D\n",
      "  Output Shape: (None, 1, 1, 1024)\n",
      "  Params: 0\n",
      "--------------------------------------------------\n",
      "Layer: dropout\n",
      "  Type: Dropout\n",
      "  Output Shape: (None, 1, 1, 1024)\n",
      "  Params: 0\n",
      "--------------------------------------------------\n",
      "Layer: conv_preds\n",
      "  Type: Conv2D\n",
      "  Output Shape: (None, 1, 1, 1000)\n",
      "  Params: 1025000\n",
      "--------------------------------------------------\n",
      "Layer: reshape_2\n",
      "  Type: Reshape\n",
      "  Output Shape: (None, 1000)\n",
      "  Params: 0\n",
      "--------------------------------------------------\n",
      "Layer: predictions\n",
      "  Type: Activation\n",
      "  Output Shape: (None, 1000)\n",
      "  Params: 0\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "base_model = MobileNet(\n",
    "    include_top=True, \n",
    "    weights='imagenet'\n",
    ")\n",
    "\n",
    "\n",
    "for layer in base_model.layers[-30:]:\n",
    "    print(f\"Layer: {layer.name}\")\n",
    "    print(f\"  Type: {layer.__class__.__name__}\")\n",
    "    print(f\"  Output Shape: {layer.output.shape}\")\n",
    "    print(f\"  Params: {layer.count_params()}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_model.trainable = False\n",
    "\n",
    "# Build model on top of MobileNet\n",
    "def get_predictions_layer(base_model_output):\n",
    "    x = GlobalAveragePooling2D()(base_model_output)\n",
    "    predictions = Dense(\n",
    "        NUM_CLASSES,\n",
    "        activation='softmax',\n",
    "        # kernel_regularizer=regularizers.l2(0.1)\n",
    "    )(x)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model architecture:\n",
      "Layer: conv_dw_11_bn\n",
      "  Type: BatchNormalization\n",
      "  Output Shape: (None, 14, 14, 512)\n",
      "  Params: 2048\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: conv_dw_11_relu\n",
      "  Type: ReLU\n",
      "  Output Shape: (None, 14, 14, 512)\n",
      "  Params: 0\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: conv_pw_11\n",
      "  Type: Conv2D\n",
      "  Output Shape: (None, 14, 14, 512)\n",
      "  Params: 262144\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: conv_pw_11_bn\n",
      "  Type: BatchNormalization\n",
      "  Output Shape: (None, 14, 14, 512)\n",
      "  Params: 2048\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: conv_pw_11_relu\n",
      "  Type: ReLU\n",
      "  Output Shape: (None, 14, 14, 512)\n",
      "  Params: 0\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: conv_pad_12\n",
      "  Type: ZeroPadding2D\n",
      "  Output Shape: (None, 15, 15, 512)\n",
      "  Params: 0\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: conv_dw_12\n",
      "  Type: DepthwiseConv2D\n",
      "  Output Shape: (None, 7, 7, 512)\n",
      "  Params: 4608\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: conv_dw_12_bn\n",
      "  Type: BatchNormalization\n",
      "  Output Shape: (None, 7, 7, 512)\n",
      "  Params: 2048\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: conv_dw_12_relu\n",
      "  Type: ReLU\n",
      "  Output Shape: (None, 7, 7, 512)\n",
      "  Params: 0\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: conv_pw_12\n",
      "  Type: Conv2D\n",
      "  Output Shape: (None, 7, 7, 1024)\n",
      "  Params: 524288\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: conv_pw_12_bn\n",
      "  Type: BatchNormalization\n",
      "  Output Shape: (None, 7, 7, 1024)\n",
      "  Params: 4096\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: conv_pw_12_relu\n",
      "  Type: ReLU\n",
      "  Output Shape: (None, 7, 7, 1024)\n",
      "  Params: 0\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: conv_dw_13\n",
      "  Type: DepthwiseConv2D\n",
      "  Output Shape: (None, 7, 7, 1024)\n",
      "  Params: 9216\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: conv_dw_13_bn\n",
      "  Type: BatchNormalization\n",
      "  Output Shape: (None, 7, 7, 1024)\n",
      "  Params: 4096\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: conv_dw_13_relu\n",
      "  Type: ReLU\n",
      "  Output Shape: (None, 7, 7, 1024)\n",
      "  Params: 0\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: conv_pw_13\n",
      "  Type: Conv2D\n",
      "  Output Shape: (None, 7, 7, 1024)\n",
      "  Params: 1048576\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: conv_pw_13_bn\n",
      "  Type: BatchNormalization\n",
      "  Output Shape: (None, 7, 7, 1024)\n",
      "  Params: 4096\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: conv_pw_13_relu\n",
      "  Type: ReLU\n",
      "  Output Shape: (None, 7, 7, 1024)\n",
      "  Params: 0\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: global_average_pooling2d_3\n",
      "  Type: GlobalAveragePooling2D\n",
      "  Output Shape: (None, 1024)\n",
      "  Params: 0\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: dense\n",
      "  Type: Dense\n",
      "  Output Shape: (None, 10)\n",
      "  Params: 10250\n",
      " Trainable: True\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "x = base_model.get_layer(\"conv_pw_13_relu\").output\n",
    "predictions = get_predictions_layer(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "for layer in model.layers[:-1]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compile model\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print('\\nModel architecture:')\n",
    "for layer in model.layers[-20:]:\n",
    "    print(f\"Layer: {layer.name}\")\n",
    "    print(f\"  Type: {layer.__class__.__name__}\")\n",
    "    print(f\"  Output Shape: {layer.output.shape}\")\n",
    "    print(f\"  Params: {layer.count_params()}\")\n",
    "    print(f\" Trainable: {layer.trainable}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6),\n",
    "    EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=validation_generator,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "model.save(\"mobilenet.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading MobileNetV2...\n",
      "Layer: block_15_expand_relu\n",
      "  Type: ReLU\n",
      "  Output Shape: (None, 7, 7, 960)\n",
      "  Params: 0\n",
      "--------------------------------------------------\n",
      "Layer: block_15_depthwise\n",
      "  Type: DepthwiseConv2D\n",
      "  Output Shape: (None, 7, 7, 960)\n",
      "  Params: 8640\n",
      "--------------------------------------------------\n",
      "Layer: block_15_depthwise_BN\n",
      "  Type: BatchNormalization\n",
      "  Output Shape: (None, 7, 7, 960)\n",
      "  Params: 3840\n",
      "--------------------------------------------------\n",
      "Layer: block_15_depthwise_relu\n",
      "  Type: ReLU\n",
      "  Output Shape: (None, 7, 7, 960)\n",
      "  Params: 0\n",
      "--------------------------------------------------\n",
      "Layer: block_15_project\n",
      "  Type: Conv2D\n",
      "  Output Shape: (None, 7, 7, 160)\n",
      "  Params: 153600\n",
      "--------------------------------------------------\n",
      "Layer: block_15_project_BN\n",
      "  Type: BatchNormalization\n",
      "  Output Shape: (None, 7, 7, 160)\n",
      "  Params: 640\n",
      "--------------------------------------------------\n",
      "Layer: block_15_add\n",
      "  Type: Add\n",
      "  Output Shape: (None, 7, 7, 160)\n",
      "  Params: 0\n",
      "--------------------------------------------------\n",
      "Layer: block_16_expand\n",
      "  Type: Conv2D\n",
      "  Output Shape: (None, 7, 7, 960)\n",
      "  Params: 153600\n",
      "--------------------------------------------------\n",
      "Layer: block_16_expand_BN\n",
      "  Type: BatchNormalization\n",
      "  Output Shape: (None, 7, 7, 960)\n",
      "  Params: 3840\n",
      "--------------------------------------------------\n",
      "Layer: block_16_expand_relu\n",
      "  Type: ReLU\n",
      "  Output Shape: (None, 7, 7, 960)\n",
      "  Params: 0\n",
      "--------------------------------------------------\n",
      "Layer: block_16_depthwise\n",
      "  Type: DepthwiseConv2D\n",
      "  Output Shape: (None, 7, 7, 960)\n",
      "  Params: 8640\n",
      "--------------------------------------------------\n",
      "Layer: block_16_depthwise_BN\n",
      "  Type: BatchNormalization\n",
      "  Output Shape: (None, 7, 7, 960)\n",
      "  Params: 3840\n",
      "--------------------------------------------------\n",
      "Layer: block_16_depthwise_relu\n",
      "  Type: ReLU\n",
      "  Output Shape: (None, 7, 7, 960)\n",
      "  Params: 0\n",
      "--------------------------------------------------\n",
      "Layer: block_16_project\n",
      "  Type: Conv2D\n",
      "  Output Shape: (None, 7, 7, 320)\n",
      "  Params: 307200\n",
      "--------------------------------------------------\n",
      "Layer: block_16_project_BN\n",
      "  Type: BatchNormalization\n",
      "  Output Shape: (None, 7, 7, 320)\n",
      "  Params: 1280\n",
      "--------------------------------------------------\n",
      "Layer: Conv_1\n",
      "  Type: Conv2D\n",
      "  Output Shape: (None, 7, 7, 1280)\n",
      "  Params: 409600\n",
      "--------------------------------------------------\n",
      "Layer: Conv_1_bn\n",
      "  Type: BatchNormalization\n",
      "  Output Shape: (None, 7, 7, 1280)\n",
      "  Params: 5120\n",
      "--------------------------------------------------\n",
      "Layer: out_relu\n",
      "  Type: ReLU\n",
      "  Output Shape: (None, 7, 7, 1280)\n",
      "  Params: 0\n",
      "--------------------------------------------------\n",
      "Layer: global_average_pooling2d_7\n",
      "  Type: GlobalAveragePooling2D\n",
      "  Output Shape: (None, 1280)\n",
      "  Params: 0\n",
      "--------------------------------------------------\n",
      "Layer: predictions\n",
      "  Type: Dense\n",
      "  Output Shape: (None, 1000)\n",
      "  Params: 1281000\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Import MobileNet and create model\n",
    "print('Loading MobileNetV2...')\n",
    "base_model = MobileNetV2(\n",
    "    include_top=True, \n",
    "    weights='imagenet'\n",
    ")\n",
    "\n",
    "for layer in base_model.layers[-20:]:\n",
    "    print(f\"Layer: {layer.name}\")\n",
    "    print(f\"  Type: {layer.__class__.__name__}\")\n",
    "    print(f\"  Output Shape: {layer.output.shape}\")\n",
    "    print(f\"  Params: {layer.count_params()}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model architecture:\n",
      "Layer: block_15_expand_relu\n",
      "  Type: ReLU\n",
      "  Output Shape: (None, 7, 7, 960)\n",
      "  Params: 0\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: block_15_depthwise\n",
      "  Type: DepthwiseConv2D\n",
      "  Output Shape: (None, 7, 7, 960)\n",
      "  Params: 8640\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: block_15_depthwise_BN\n",
      "  Type: BatchNormalization\n",
      "  Output Shape: (None, 7, 7, 960)\n",
      "  Params: 3840\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: block_15_depthwise_relu\n",
      "  Type: ReLU\n",
      "  Output Shape: (None, 7, 7, 960)\n",
      "  Params: 0\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: block_15_project\n",
      "  Type: Conv2D\n",
      "  Output Shape: (None, 7, 7, 160)\n",
      "  Params: 153600\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: block_15_project_BN\n",
      "  Type: BatchNormalization\n",
      "  Output Shape: (None, 7, 7, 160)\n",
      "  Params: 640\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: block_15_add\n",
      "  Type: Add\n",
      "  Output Shape: (None, 7, 7, 160)\n",
      "  Params: 0\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: block_16_expand\n",
      "  Type: Conv2D\n",
      "  Output Shape: (None, 7, 7, 960)\n",
      "  Params: 153600\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: block_16_expand_BN\n",
      "  Type: BatchNormalization\n",
      "  Output Shape: (None, 7, 7, 960)\n",
      "  Params: 3840\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: block_16_expand_relu\n",
      "  Type: ReLU\n",
      "  Output Shape: (None, 7, 7, 960)\n",
      "  Params: 0\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: block_16_depthwise\n",
      "  Type: DepthwiseConv2D\n",
      "  Output Shape: (None, 7, 7, 960)\n",
      "  Params: 8640\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: block_16_depthwise_BN\n",
      "  Type: BatchNormalization\n",
      "  Output Shape: (None, 7, 7, 960)\n",
      "  Params: 3840\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: block_16_depthwise_relu\n",
      "  Type: ReLU\n",
      "  Output Shape: (None, 7, 7, 960)\n",
      "  Params: 0\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: block_16_project\n",
      "  Type: Conv2D\n",
      "  Output Shape: (None, 7, 7, 320)\n",
      "  Params: 307200\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: block_16_project_BN\n",
      "  Type: BatchNormalization\n",
      "  Output Shape: (None, 7, 7, 320)\n",
      "  Params: 1280\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: Conv_1\n",
      "  Type: Conv2D\n",
      "  Output Shape: (None, 7, 7, 1280)\n",
      "  Params: 409600\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: Conv_1_bn\n",
      "  Type: BatchNormalization\n",
      "  Output Shape: (None, 7, 7, 1280)\n",
      "  Params: 5120\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: out_relu\n",
      "  Type: ReLU\n",
      "  Output Shape: (None, 7, 7, 1280)\n",
      "  Params: 0\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: global_average_pooling2d_8\n",
      "  Type: GlobalAveragePooling2D\n",
      "  Output Shape: (None, 1280)\n",
      "  Params: 0\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: dense_2\n",
      "  Type: Dense\n",
      "  Output Shape: (None, 10)\n",
      "  Params: 12810\n",
      " Trainable: True\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "x = base_model.get_layer(\"out_relu\").output\n",
    "predictions = get_predictions_layer(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "for layer in model.layers[:-1]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compile model\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print('\\nModel architecture:')\n",
    "for layer in model.layers[-20:]:\n",
    "    print(f\"Layer: {layer.name}\")\n",
    "    print(f\"  Type: {layer.__class__.__name__}\")\n",
    "    print(f\"  Output Shape: {layer.output.shape}\")\n",
    "    print(f\"  Params: {layer.count_params()}\")\n",
    "    print(f\" Trainable: {layer.trainable}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "Epoch 1/30\n",
      "45/45 [==============================] - 26s 534ms/step - loss: 1.4617 - accuracy: 0.5188 - val_loss: 1.1626 - val_accuracy: 0.5903 - lr: 0.0010\n",
      "Epoch 2/30\n",
      "45/45 [==============================] - 11s 249ms/step - loss: 0.7479 - accuracy: 0.7970 - val_loss: 0.9570 - val_accuracy: 0.6734 - lr: 0.0010\n",
      "Epoch 3/30\n",
      "45/45 [==============================] - 11s 249ms/step - loss: 0.5975 - accuracy: 0.8119 - val_loss: 0.7597 - val_accuracy: 0.7622 - lr: 0.0010\n",
      "Epoch 4/30\n",
      "45/45 [==============================] - 11s 253ms/step - loss: 0.4881 - accuracy: 0.8531 - val_loss: 0.7331 - val_accuracy: 0.7736 - lr: 0.0010\n",
      "Epoch 5/30\n",
      "45/45 [==============================] - 11s 254ms/step - loss: 0.4061 - accuracy: 0.8907 - val_loss: 0.6866 - val_accuracy: 0.7880 - lr: 0.0010\n",
      "Epoch 6/30\n",
      "45/45 [==============================] - 11s 248ms/step - loss: 0.3640 - accuracy: 0.9042 - val_loss: 0.6776 - val_accuracy: 0.7851 - lr: 0.0010\n",
      "Epoch 7/30\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.3309 - accuracy: 0.9127 - val_loss: 0.7625 - val_accuracy: 0.7679 - lr: 0.0010\n",
      "Epoch 8/30\n",
      "45/45 [==============================] - 11s 256ms/step - loss: 0.3043 - accuracy: 0.9155 - val_loss: 0.6080 - val_accuracy: 0.8023 - lr: 0.0010\n",
      "Epoch 9/30\n",
      "45/45 [==============================] - 11s 248ms/step - loss: 0.2922 - accuracy: 0.9248 - val_loss: 0.6177 - val_accuracy: 0.8023 - lr: 0.0010\n",
      "Epoch 10/30\n",
      "45/45 [==============================] - 12s 259ms/step - loss: 0.2691 - accuracy: 0.9283 - val_loss: 0.5761 - val_accuracy: 0.8052 - lr: 0.0010\n",
      "Epoch 11/30\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.2574 - accuracy: 0.9368 - val_loss: 0.5713 - val_accuracy: 0.8252 - lr: 0.0010\n",
      "Epoch 12/30\n",
      "45/45 [==============================] - 11s 249ms/step - loss: 0.2426 - accuracy: 0.9297 - val_loss: 0.6349 - val_accuracy: 0.8023 - lr: 0.0010\n",
      "Epoch 13/30\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.2228 - accuracy: 0.9432 - val_loss: 0.5155 - val_accuracy: 0.8309 - lr: 0.0010\n",
      "Epoch 14/30\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.2523 - accuracy: 0.9262 - val_loss: 0.5794 - val_accuracy: 0.8023 - lr: 0.0010\n",
      "Epoch 15/30\n",
      "45/45 [==============================] - 11s 254ms/step - loss: 0.2087 - accuracy: 0.9475 - val_loss: 0.5913 - val_accuracy: 0.7994 - lr: 0.0010\n",
      "Epoch 16/30\n",
      "45/45 [==============================] - 11s 249ms/step - loss: 0.2225 - accuracy: 0.9368 - val_loss: 0.5819 - val_accuracy: 0.8166 - lr: 0.0010\n",
      "Epoch 17/30\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.1860 - accuracy: 0.9475 - val_loss: 0.5259 - val_accuracy: 0.8109 - lr: 5.0000e-04\n",
      "Epoch 18/30\n",
      "45/45 [==============================] - 11s 252ms/step - loss: 0.1857 - accuracy: 0.9631 - val_loss: 0.5215 - val_accuracy: 0.8195 - lr: 5.0000e-04\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=validation_generator,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "model.save(\"mobilenet2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nahuel/programming/ML/sign-language-digits/venv/lib/python3.12/site-packages/keras/src/applications/mobilenet_v3.py:454: UserWarning: `input_shape` is undefined or non-square, or `rows` is not 224. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  return MobileNetV3(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v3/weights_mobilenet_v3_small_224_1.0_float.h5\n",
      "\u001b[1m10734624/10734624\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 0us/step\n",
      "Layer: re_lu_31\n",
      "  Type: ReLU\n",
      "  Output Shape: (None, 1, 1, 576)\n",
      "  Params: 0\n",
      "--------------------------------------------------\n",
      "Layer: expanded_conv_9_squeeze_excite_mul\n",
      "  Type: Multiply\n",
      "  Output Shape: (None, None, None, 576)\n",
      "  Params: 0\n",
      "--------------------------------------------------\n",
      "Layer: expanded_conv_9_project\n",
      "  Type: Conv2D\n",
      "  Output Shape: (None, None, None, 96)\n",
      "  Params: 55296\n",
      "--------------------------------------------------\n",
      "Layer: expanded_conv_9_project_bn\n",
      "  Type: BatchNormalization\n",
      "  Output Shape: (None, None, None, 96)\n",
      "  Params: 384\n",
      "--------------------------------------------------\n",
      "Layer: expanded_conv_9_add\n",
      "  Type: Add\n",
      "  Output Shape: (None, None, None, 96)\n",
      "  Params: 0\n",
      "--------------------------------------------------\n",
      "Layer: expanded_conv_10_expand\n",
      "  Type: Conv2D\n",
      "  Output Shape: (None, None, None, 576)\n",
      "  Params: 55296\n",
      "--------------------------------------------------\n",
      "Layer: expanded_conv_10_expand_bn\n",
      "  Type: BatchNormalization\n",
      "  Output Shape: (None, None, None, 576)\n",
      "  Params: 2304\n",
      "--------------------------------------------------\n",
      "Layer: activation_36\n",
      "  Type: Activation\n",
      "  Output Shape: (None, None, None, 576)\n",
      "  Params: 0\n",
      "--------------------------------------------------\n",
      "Layer: expanded_conv_10_depthwise\n",
      "  Type: DepthwiseConv2D\n",
      "  Output Shape: (None, None, None, 576)\n",
      "  Params: 14400\n",
      "--------------------------------------------------\n",
      "Layer: expanded_conv_10_depthwise_bn\n",
      "  Type: BatchNormalization\n",
      "  Output Shape: (None, None, None, 576)\n",
      "  Params: 2304\n",
      "--------------------------------------------------\n",
      "Layer: activation_37\n",
      "  Type: Activation\n",
      "  Output Shape: (None, None, None, 576)\n",
      "  Params: 0\n",
      "--------------------------------------------------\n",
      "Layer: expanded_conv_10_squeeze_excite_avg_pool\n",
      "  Type: GlobalAveragePooling2D\n",
      "  Output Shape: (None, 1, 1, 576)\n",
      "  Params: 0\n",
      "--------------------------------------------------\n",
      "Layer: expanded_conv_10_squeeze_excite_conv\n",
      "  Type: Conv2D\n",
      "  Output Shape: (None, 1, 1, 144)\n",
      "  Params: 83088\n",
      "--------------------------------------------------\n",
      "Layer: expanded_conv_10_squeeze_excite_relu\n",
      "  Type: ReLU\n",
      "  Output Shape: (None, 1, 1, 144)\n",
      "  Params: 0\n",
      "--------------------------------------------------\n",
      "Layer: expanded_conv_10_squeeze_excite_conv_1\n",
      "  Type: Conv2D\n",
      "  Output Shape: (None, 1, 1, 576)\n",
      "  Params: 83520\n",
      "--------------------------------------------------\n",
      "Layer: re_lu_32\n",
      "  Type: ReLU\n",
      "  Output Shape: (None, 1, 1, 576)\n",
      "  Params: 0\n",
      "--------------------------------------------------\n",
      "Layer: expanded_conv_10_squeeze_excite_mul\n",
      "  Type: Multiply\n",
      "  Output Shape: (None, None, None, 576)\n",
      "  Params: 0\n",
      "--------------------------------------------------\n",
      "Layer: expanded_conv_10_project\n",
      "  Type: Conv2D\n",
      "  Output Shape: (None, None, None, 96)\n",
      "  Params: 55296\n",
      "--------------------------------------------------\n",
      "Layer: expanded_conv_10_project_bn\n",
      "  Type: BatchNormalization\n",
      "  Output Shape: (None, None, None, 96)\n",
      "  Params: 384\n",
      "--------------------------------------------------\n",
      "Layer: expanded_conv_10_add\n",
      "  Type: Add\n",
      "  Output Shape: (None, None, None, 96)\n",
      "  Params: 0\n",
      "--------------------------------------------------\n",
      "Layer: conv_1\n",
      "  Type: Conv2D\n",
      "  Output Shape: (None, None, None, 576)\n",
      "  Params: 55296\n",
      "--------------------------------------------------\n",
      "Layer: conv_1_bn\n",
      "  Type: BatchNormalization\n",
      "  Output Shape: (None, None, None, 576)\n",
      "  Params: 2304\n",
      "--------------------------------------------------\n",
      "Layer: activation_38\n",
      "  Type: Activation\n",
      "  Output Shape: (None, None, None, 576)\n",
      "  Params: 0\n",
      "--------------------------------------------------\n",
      "Layer: global_average_pooling2d_5\n",
      "  Type: GlobalAveragePooling2D\n",
      "  Output Shape: (None, 1, 1, 576)\n",
      "  Params: 0\n",
      "--------------------------------------------------\n",
      "Layer: conv_2\n",
      "  Type: Conv2D\n",
      "  Output Shape: (None, 1, 1, 1024)\n",
      "  Params: 590848\n",
      "--------------------------------------------------\n",
      "Layer: activation_39\n",
      "  Type: Activation\n",
      "  Output Shape: (None, 1, 1, 1024)\n",
      "  Params: 0\n",
      "--------------------------------------------------\n",
      "Layer: dropout_1\n",
      "  Type: Dropout\n",
      "  Output Shape: (None, 1, 1, 1024)\n",
      "  Params: 0\n",
      "--------------------------------------------------\n",
      "Layer: logits\n",
      "  Type: Conv2D\n",
      "  Output Shape: (None, 1, 1, 1000)\n",
      "  Params: 1025000\n",
      "--------------------------------------------------\n",
      "Layer: flatten_1\n",
      "  Type: Flatten\n",
      "  Output Shape: (None, 1000)\n",
      "  Params: 0\n",
      "--------------------------------------------------\n",
      "Layer: predictions\n",
      "  Type: Activation\n",
      "  Output Shape: (None, 1000)\n",
      "  Params: 0\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "base_model = MobileNetV3Small(\n",
    "    include_top=True, \n",
    "    weights='imagenet'\n",
    ")\n",
    "\n",
    "\n",
    "for layer in base_model.layers[-30:]:\n",
    "    print(f\"Layer: {layer.name}\")\n",
    "    print(f\"  Type: {layer.__class__.__name__}\")\n",
    "    print(f\"  Output Shape: {layer.output.shape}\")\n",
    "    print(f\"  Params: {layer.count_params()}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model architecture:\n",
      "Layer: expanded_conv_10_expand\n",
      "  Type: Conv2D\n",
      "  Output Shape: (None, None, None, 576)\n",
      "  Params: 55296\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: expanded_conv_10_expand_bn\n",
      "  Type: BatchNormalization\n",
      "  Output Shape: (None, None, None, 576)\n",
      "  Params: 2304\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: activation_36\n",
      "  Type: Activation\n",
      "  Output Shape: (None, None, None, 576)\n",
      "  Params: 0\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: expanded_conv_10_depthwise\n",
      "  Type: DepthwiseConv2D\n",
      "  Output Shape: (None, None, None, 576)\n",
      "  Params: 14400\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: expanded_conv_10_depthwise_bn\n",
      "  Type: BatchNormalization\n",
      "  Output Shape: (None, None, None, 576)\n",
      "  Params: 2304\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: activation_37\n",
      "  Type: Activation\n",
      "  Output Shape: (None, None, None, 576)\n",
      "  Params: 0\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: expanded_conv_10_squeeze_excite_avg_pool\n",
      "  Type: GlobalAveragePooling2D\n",
      "  Output Shape: (None, 1, 1, 576)\n",
      "  Params: 0\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: expanded_conv_10_squeeze_excite_conv\n",
      "  Type: Conv2D\n",
      "  Output Shape: (None, 1, 1, 144)\n",
      "  Params: 83088\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: expanded_conv_10_squeeze_excite_relu\n",
      "  Type: ReLU\n",
      "  Output Shape: (None, 1, 1, 144)\n",
      "  Params: 0\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: expanded_conv_10_squeeze_excite_conv_1\n",
      "  Type: Conv2D\n",
      "  Output Shape: (None, 1, 1, 576)\n",
      "  Params: 83520\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: re_lu_32\n",
      "  Type: ReLU\n",
      "  Output Shape: (None, 1, 1, 576)\n",
      "  Params: 0\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: expanded_conv_10_squeeze_excite_mul\n",
      "  Type: Multiply\n",
      "  Output Shape: (None, None, None, 576)\n",
      "  Params: 0\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: expanded_conv_10_project\n",
      "  Type: Conv2D\n",
      "  Output Shape: (None, None, None, 96)\n",
      "  Params: 55296\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: expanded_conv_10_project_bn\n",
      "  Type: BatchNormalization\n",
      "  Output Shape: (None, None, None, 96)\n",
      "  Params: 384\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: expanded_conv_10_add\n",
      "  Type: Add\n",
      "  Output Shape: (None, None, None, 96)\n",
      "  Params: 0\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: conv_1\n",
      "  Type: Conv2D\n",
      "  Output Shape: (None, None, None, 576)\n",
      "  Params: 55296\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: conv_1_bn\n",
      "  Type: BatchNormalization\n",
      "  Output Shape: (None, None, None, 576)\n",
      "  Params: 2304\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: activation_38\n",
      "  Type: Activation\n",
      "  Output Shape: (None, None, None, 576)\n",
      "  Params: 0\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: global_average_pooling2d_6\n",
      "  Type: GlobalAveragePooling2D\n",
      "  Output Shape: (None, 576)\n",
      "  Params: 0\n",
      " Trainable: False\n",
      "--------------------------------------------------\n",
      "Layer: dense_1\n",
      "  Type: Dense\n",
      "  Output Shape: (None, 10)\n",
      "  Params: 5770\n",
      " Trainable: True\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "x = base_model.get_layer(\"activation_38\").output\n",
    "predictions = get_predictions_layer(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "for layer in model.layers[:-1]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compile model\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print('\\nModel architecture:')\n",
    "for layer in model.layers[-20:]:\n",
    "    print(f\"Layer: {layer.name}\")\n",
    "    print(f\"  Type: {layer.__class__.__name__}\")\n",
    "    print(f\"  Output Shape: {layer.output.shape}\")\n",
    "    print(f\"  Params: {layer.count_params()}\")\n",
    "    print(f\" Trainable: {layer.trainable}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=validation_generator,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "model.save(\"mobilenet3.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded!\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "model_path = Path('basic.h5')\n",
    "\n",
    "if model_path.exists():\n",
    "    model2 = load_model(model_path)\n",
    "    print(\"Model loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "45/45 [==============================] - 14s 261ms/step - loss: 0.2097 - accuracy: 0.9510 - val_loss: 0.5089 - val_accuracy: 0.8309 - lr: 1.0000e-04\n",
      "Epoch 2/30\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.2117 - accuracy: 0.9546 - val_loss: 0.5058 - val_accuracy: 0.8338 - lr: 1.0000e-04\n",
      "Epoch 3/30\n",
      "45/45 [==============================] - 11s 248ms/step - loss: 0.2187 - accuracy: 0.9432 - val_loss: 0.5061 - val_accuracy: 0.8338 - lr: 1.0000e-04\n",
      "Epoch 4/30\n",
      "45/45 [==============================] - 11s 252ms/step - loss: 0.2045 - accuracy: 0.9546 - val_loss: 0.5070 - val_accuracy: 0.8309 - lr: 1.0000e-04\n",
      "Epoch 5/30\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.2103 - accuracy: 0.9553 - val_loss: 0.5089 - val_accuracy: 0.8281 - lr: 1.0000e-04\n",
      "Epoch 6/30\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.2102 - accuracy: 0.9517 - val_loss: 0.5083 - val_accuracy: 0.8281 - lr: 5.0000e-05\n",
      "Epoch 7/30\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.2163 - accuracy: 0.9432 - val_loss: 0.5076 - val_accuracy: 0.8309 - lr: 5.0000e-05\n",
      "Epoch 8/30\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.2104 - accuracy: 0.9496 - val_loss: 0.5043 - val_accuracy: 0.8309 - lr: 5.0000e-05\n",
      "Epoch 9/30\n",
      "45/45 [==============================] - 11s 252ms/step - loss: 0.2050 - accuracy: 0.9539 - val_loss: 0.5025 - val_accuracy: 0.8367 - lr: 5.0000e-05\n",
      "Epoch 10/30\n",
      "45/45 [==============================] - 11s 248ms/step - loss: 0.2034 - accuracy: 0.9567 - val_loss: 0.5044 - val_accuracy: 0.8367 - lr: 5.0000e-05\n",
      "Epoch 11/30\n",
      "45/45 [==============================] - 11s 249ms/step - loss: 0.2027 - accuracy: 0.9574 - val_loss: 0.5026 - val_accuracy: 0.8338 - lr: 5.0000e-05\n",
      "Epoch 12/30\n",
      "45/45 [==============================] - 11s 254ms/step - loss: 0.2018 - accuracy: 0.9517 - val_loss: 0.5002 - val_accuracy: 0.8367 - lr: 5.0000e-05\n",
      "Epoch 13/30\n",
      "45/45 [==============================] - 11s 249ms/step - loss: 0.2095 - accuracy: 0.9468 - val_loss: 0.5006 - val_accuracy: 0.8367 - lr: 5.0000e-05\n",
      "Epoch 14/30\n",
      "45/45 [==============================] - 11s 249ms/step - loss: 0.2095 - accuracy: 0.9454 - val_loss: 0.5023 - val_accuracy: 0.8367 - lr: 5.0000e-05\n",
      "Epoch 15/30\n",
      "45/45 [==============================] - 12s 255ms/step - loss: 0.2094 - accuracy: 0.9489 - val_loss: 0.5049 - val_accuracy: 0.8338 - lr: 5.0000e-05\n",
      "Epoch 16/30\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.2035 - accuracy: 0.9524 - val_loss: 0.5039 - val_accuracy: 0.8338 - lr: 2.5000e-05\n",
      "Epoch 17/30\n",
      "45/45 [==============================] - 11s 249ms/step - loss: 0.2053 - accuracy: 0.9425 - val_loss: 0.5029 - val_accuracy: 0.8338 - lr: 2.5000e-05\n",
      "Epoch 18/30\n",
      "45/45 [==============================] - 11s 248ms/step - loss: 0.2181 - accuracy: 0.9496 - val_loss: 0.5039 - val_accuracy: 0.8338 - lr: 2.5000e-05\n",
      "Epoch 19/30\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.2039 - accuracy: 0.9510 - val_loss: 0.5033 - val_accuracy: 0.8338 - lr: 1.2500e-05\n",
      "Epoch 20/30\n",
      "45/45 [==============================] - 11s 254ms/step - loss: 0.2002 - accuracy: 0.9553 - val_loss: 0.5030 - val_accuracy: 0.8338 - lr: 1.2500e-05\n",
      "Epoch 21/30\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.2075 - accuracy: 0.9496 - val_loss: 0.5036 - val_accuracy: 0.8338 - lr: 1.2500e-05\n",
      "Epoch 22/30\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.2060 - accuracy: 0.9482 - val_loss: 0.5034 - val_accuracy: 0.8338 - lr: 6.2500e-06\n"
     ]
    }
   ],
   "source": [
    "for layer in model2.layers[:-20]:\n",
    "    layer.trainable = False\n",
    "\n",
    "model2.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "callbacks = [\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6),\n",
    "    EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "]\n",
    "\n",
    "history = model2.fit(\n",
    "    train_generator,\n",
    "    validation_data=validation_generator,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualize Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Evaluate Model\n",
    "Testing on unseen eval dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model on eval/ folder\n",
    "eval_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "eval_generator = eval_datagen.flow_from_directory(\n",
    "    EVAL_PATH,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "print('Evaluating model on eval dataset...')\n",
    "eval_loss, eval_accuracy = model.evaluate(eval_generator)\n",
    "print(f'\\nEval Loss: {eval_loss:.4f}')\n",
    "print(f'Eval Accuracy: {eval_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Confusion Matrix & Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions for confusion matrix\n",
    "eval_generator.reset()\n",
    "predictions = model.predict(eval_generator, verbose=1)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "true_classes = eval_generator.classes\n",
    "\n",
    "# Create confusion matrix\n",
    "cm = confusion_matrix(true_classes, predicted_classes)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=range(10), yticklabels=range(10))\n",
    "plt.title('Confusion Matrix - Sign Language Digits')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.show()\n",
    "\n",
    "# Print classification report\n",
    "print('\\nClassification Report:')\n",
    "print(classification_report(true_classes, predicted_classes, \n",
    "                          target_names=[str(i) for i in range(10)]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
